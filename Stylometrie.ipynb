{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fab4cd",
   "metadata": {},
   "source": [
    "# Le but de ce notebook est d'identifier des caractéristiques permettant de différencier des textes écrits par Molière et Corneille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b1ff2",
   "metadata": {},
   "source": [
    "# Installation des modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aecb3f",
   "metadata": {},
   "source": [
    "# PRIVE: Hyperparamétres fixés par MathAData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da83bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de caractéres dans chaque paragraphe dont on veut identifier l'auteur\n",
    "# 1000 caractères correspond à environ une page de texte (environ 180 mots)\n",
    "min_paragraph_length = 1000\n",
    "\n",
    "# on divise les données d'entraînement en 90% en train et 10% en validation\n",
    "# une oeuvre d'un auteur donné doit être entièrement soit en train soit en validation\n",
    "percentage_in_train = 0.9\n",
    "\n",
    "# on ignore les majuscules / minuscules dans les mots: Monsieur == monsieur\n",
    "use_lowercase = True\n",
    "\n",
    "# on ignore les accents:  être == etre\n",
    "use_diacritics = True\n",
    "\n",
    "# nombre de mots signatures chez chaque auteur\n",
    "# on ne garde que les 'most_common_normalized_words_count' mots les plus courants chez les auteurs\n",
    "most_common_normalized_words_count = 100\n",
    "\n",
    "# Mots vides. \n",
    "# Ils sont ignorés par l'outil car très communs à la fois chez Molière et chez Corneille\n",
    "stop_words = set([\"de\",\"et\",\"que\",\"je\",\"a\",\"la\",\"le\",\"ne\",\"ce\",\"il\",\"pour\",\"un\",\"qui\",\"me\",\"est\",\"mais\",\"des\",\"moi\",\"votre\",\"qu'il\",\"lui\",\"du\",\"fait\",\"par\",\"se\",\"au\",\"cette\",\"sur\",\"j'ai\",\"avec\",\"tous\",\"vos\",\"ces\",\"n'est\",\"peu\",\"peut\",\"quelque\",\"dont\",\"quoi\",\"aux\",\"donc\",\"d'une\",\"s'il\",\"notre\",\"sais\",\"donne\",\"vois\",\"m'en\",\"cet\",\"autre\",\"puis\",\"assez\",\"quel\",\"veut\",\"va\",\"ils\",\"doit\",\"ont\",\"vu\", \"en\", \"les\", \"vous\", \"mon\",\"pas\",\"si\",\"plus\", \"tout\", \"nous\", \"ma\", \"sans\", \"ou\", \"c'est\", \"bien\", \"dans\",\"une\", \"son\",\"tu\", \"point\", \"mais\", \"mes\", \"d'un\", \"elle\", \"ses\", \"meme\", \"comme\", \"te\", \"sa\", \"ton\", \"ta\", \"sganarelle\",\"jourdain\",\"mascarille\", \"dom\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82185316",
   "metadata": {},
   "source": [
    "# PRIVE: Méthodes utilisés dans le Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09dcc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import List,Set,Tuple,Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter,MaxNLocator     \n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# le répertoire de travail\n",
    "directory = os.path.abspath('')\n",
    "random.seed(42)\n",
    "\n",
    "# retourne tous les fichiers *.txt présents dans le repertoire 'path'\n",
    "def all_txt_files_in_directory(path: str):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.txt')]\n",
    "\n",
    "# infique si la ligne 'ligne' est une ligne valide ou si elle doit être ignorée (par exemple si elle vide)\n",
    "def is_valid_line(line: str) -> bool:\n",
    "    if line.startswith('Scène ') or line.startswith('Acte '):\n",
    "        return False\n",
    "    if len(line)<10:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def split_book_into_paragraphs(path: str) -> List[str]:\n",
    "    result = []\n",
    "    with open(path, encoding='latin1') as file:\n",
    "        current_paragraph = \"\"\n",
    "        for line in file:\n",
    "            if is_valid_line(line):\n",
    "                if current_paragraph :\n",
    "                    current_paragraph += \"\\n\"\n",
    "                current_paragraph += line.rstrip()\n",
    "                if len(current_paragraph) >= min_paragraph_length:\n",
    "                    result.append(current_paragraph) \n",
    "                    current_paragraph = \"\"\n",
    "    if len(current_paragraph) >= min_paragraph_length or (current_paragraph and len(result) == 0):\n",
    "        result.append(current_paragraph) \n",
    "    return result\n",
    "\n",
    "def load_all_books(path: str) -> Dict[str,List[str]]:\n",
    "    book_to_paragraphs = dict()\n",
    "    for book_path in all_txt_files_in_directory(path):\n",
    "        book_to_paragraphs[pathlib.Path(book_path).stem] = split_book_into_paragraphs(book_path)\n",
    "    return book_to_paragraphs\n",
    "\n",
    "# pour supprimer les accents\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def remove_diacritics(word: str) -> str:\n",
    "    import unidecode  \n",
    "    return unidecode.unidecode(word)\n",
    "\n",
    "# mots en minuscules\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def to_lowercase(word: str) -> str:\n",
    "    return word.lower()\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_normalized_word(word: str) -> str:\n",
    "    if use_lowercase:\n",
    "        word = to_lowercase(word)\n",
    "    if use_diacritics:\n",
    "        word = remove_diacritics(word)\n",
    "    return word\n",
    "\n",
    "def paragraph_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    if not book_to_paragraphs:\n",
    "        return 0\n",
    "    return sum([len(c) for c in book_to_paragraphs.values()])\n",
    "\n",
    "def split_text(text:str) -> List[str]:\n",
    "    return re.findall(r\"\\b[\\w'^\\d]+\\b\", text.rstrip())\n",
    "            \n",
    "def word_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    result = 0\n",
    "    for paragraph in all_paragraphs(book_to_paragraphs):\n",
    "        result += len(split_text(paragraph.rstrip()))\n",
    "    return result\n",
    "\n",
    "def all_paragraphs(book_to_paragraphs: Dict[str, List[str]]) -> List[str]:\n",
    "    result = []\n",
    "    for p in book_to_paragraphs.values():\n",
    "        result.extend(p)\n",
    "    return result\n",
    "\n",
    "# reduce the dataset so that it contains exactly 'target_count' paragraphs\n",
    "def reduce_to_paragraph_count(book_to_paragraphs: dict, target_count: int ) -> int:\n",
    "    current_count = paragraph_count(book_to_paragraphs)\n",
    "    if current_count<target_count:\n",
    "        raise Exception(f'current_count {current_count} < target_count {target_count}')\n",
    "    to_remove = current_count-  target_count\n",
    "    result = dict()\n",
    "    for book, paragraphs in sorted(book_to_paragraphs.items(), key =lambda x : len(x[1])):\n",
    "        if len(paragraphs)<=to_remove:\n",
    "            to_remove-=len(paragraphs)\n",
    "            continue\n",
    "        result[book] = paragraphs[:len(paragraphs)-to_remove]\n",
    "        to_remove = 0\n",
    "    return result\n",
    "\n",
    "def compute_normalized_words_to_stats_without_stop_words(paragraphs: List[str]) -> Dict[str, Tuple[int,Dict[str,int]] ]:\n",
    "    normalized_words_to_stats = dict()\n",
    "    for paragraph in paragraphs:\n",
    "        words = split_text(paragraph)\n",
    "        for original_word in words:\n",
    "            normalized_word = compute_normalized_word(original_word)\n",
    "            if normalized_word in stop_words:\n",
    "                continue\n",
    "            if normalized_word not in normalized_words_to_stats:\n",
    "                normalized_words_to_stats[normalized_word] = (0, dict())\n",
    "            count,original_word_count = normalized_words_to_stats[normalized_word]\n",
    "            if original_word not in original_word_count:\n",
    "                original_word_count[original_word] = 1\n",
    "            else:\n",
    "                original_word_count[original_word] += 1\n",
    "            normalized_words_to_stats[normalized_word] = (count+1,original_word_count)\n",
    "    return normalized_words_to_stats\n",
    "\n",
    "def split_train_validation_single_author(book_to_paragraphs: dict, percentage_in_train:float) :\n",
    "    books = list(book_to_paragraphs.keys())\n",
    "    train = dict()\n",
    "    validation = dict()\n",
    "    for book, paragraphs in book_to_paragraphs.items():\n",
    "        paragraphs_count = len(paragraphs)\n",
    "        percentage_in_train_if_adding_to_train = (paragraph_count(train)+len(paragraphs))/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        percentage_in_train_if_adding_to_validation = paragraph_count(train)/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        if abs(percentage_in_train_if_adding_to_train-percentage_in_train)<abs(percentage_in_train_if_adding_to_validation-percentage_in_train):\n",
    "            train[book] = paragraphs\n",
    "        else:\n",
    "            validation[book] = paragraphs\n",
    "    return train, validation\n",
    "\n",
    "def split_train_validation_all_authors(book_to_paragraphs_author1: dict, book_to_paragraphs_author2: dict, percentage_in_train:float) :\n",
    "    train_author1,validation_author1 = split_train_validation_single_author(book_to_paragraphs_author1, percentage_in_train)\n",
    "    train_author2,validation_author2 = split_train_validation_single_author(book_to_paragraphs_author2, percentage_in_train)\n",
    "\n",
    "    target_length_validation = min(paragraph_count(validation_author1),paragraph_count(validation_author2))            \n",
    "    validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "    validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "\n",
    "    target_length_train = min(paragraph_count(train_author1),paragraph_count(train_author2))            \n",
    "    train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "    train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "\n",
    "    proportion_in_train = target_length_train/(target_length_train+target_length_validation)\n",
    "    if proportion_in_train>percentage_in_train:\n",
    "        target_length_train = int( (percentage_in_train/(1-percentage_in_train)) *target_length_validation )\n",
    "        train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "        train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "    else:\n",
    "        target_length_validation = int( ((1-percentage_in_train)/percentage_in_train) *target_length_train )\n",
    "        validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "        validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "    return train_author1,validation_author1,train_author2,validation_author2\n",
    "\n",
    "def calcul_erreur(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1-(TP+TN)/max(TP+TN+FP+FN,1)\n",
    "\n",
    "def valeur_caracteristique(text:str, index_left:int, index_right:int) -> float:\n",
    "    values = compute_words_count_in_text(text)\n",
    "    return 100*sum(values[index_left: index_right+1])/sum(values)\n",
    "\n",
    "def calcul_confusion_matrix_1_caracteristique(text_moliere: List[str], text_corneille: List[str], index_left:int, index_right:int, seuil_caracteristique:float) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = Molière ,  y_pred = Molière\n",
    "    TN = 0 # y_true = Corneille, y_pred = Corneille\n",
    "    FN = 0 # y_true = Molière,   y_pred = Corneille\n",
    "    FP = 0 # y_true = Corneille, y_pred = Molière \n",
    "    for t in text_moliere:\n",
    "        if valeur_caracteristique(t, index_left, index_right) > seuil_caracteristique:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    for t in text_corneille:\n",
    "        if valeur_caracteristique(t, index_left, index_right) > seuil_caracteristique:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "    \n",
    "def calcul_validation_erreur_moliere_vs_corneille_1_caracteristique(index_left:int, index_right:int, seuil_caracteristique:float) -> Tuple[float,float]:\n",
    "    return calcul_erreur(*calcul_confusion_matrix_1_caracteristique(all_paragraphs(moliere_validation_dataset), all_paragraphs(corneille_validation_dataset), index_left, index_right, seuil_caracteristique))\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_words_count_in_text(text: str) -> List[int]:\n",
    "    word_to_index = dict()\n",
    "    for i in range (0, most_common_normalized_words_count):\n",
    "        word_to_index[most_used_words[i]] = i\n",
    "    res = [0] * most_common_normalized_words_count\n",
    "        \n",
    "    for original_word in split_text(text):\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in word_to_index:\n",
    "            res[word_to_index[normalized_word]] += 1\n",
    "    return res\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def get_values_mean_mode_interquartiles_indexes(text: str) -> Tuple[ List[int], float, float, float, float, float ]:\n",
    "    values = compute_words_count_in_text(text)\n",
    "    total = sum(values)\n",
    "    index_Q1 = -1\n",
    "    index_median_Q2 = -1\n",
    "    index_Q3 = -1\n",
    "    values_sum = 0\n",
    "    values_sum_left = 0\n",
    "    total_sum = 0\n",
    "    index_mode = 0\n",
    "    for i in range(0, len(values)):\n",
    "        values_sum += values[i]\n",
    "        if i<(len(values)/2):\n",
    "            values_sum_left += values[i]\n",
    "        if values[i] > values[index_mode]:\n",
    "            index_mode = i            \n",
    "        total_sum += (i+1)*values[i]\n",
    "        if index_Q1 ==-1 and values_sum>=(0.25*total):\n",
    "            index_Q1 = i\n",
    "        if index_median_Q2 ==-1 and values_sum>=(0.5*total):\n",
    "            index_median_Q2 = i\n",
    "        if index_Q3 ==-1 and values_sum>=(0.75*total):\n",
    "            index_Q3 = i\n",
    "    return (values, total_sum/values_sum, 100-100*values_sum_left/values_sum, index_mode, index_Q1, index_median_Q2, index_Q3)\n",
    "\n",
    "def affiche_erreur_1_caracteristique(index_left:int, index_right:int):\n",
    "    seuil_caracteristiques = list(np.arange(0,1.00001,0.01))\n",
    "    erreur_for_seuil_caracteristiques = []\n",
    "    \n",
    "    min_seuil_caracteristique = None\n",
    "    min_validation_erreur = None\n",
    "    \n",
    "    for seuil_caracteristique in seuil_caracteristiques:\n",
    "        validation_erreur = calcul_validation_erreur_moliere_vs_corneille_1_caracteristique(index_left, index_right, 100*seuil_caracteristique)\n",
    "        erreur_for_seuil_caracteristiques.append(validation_erreur)\n",
    "        if min_seuil_caracteristique is None or validation_erreur< min_validation_erreur:\n",
    "            min_seuil_caracteristique = seuil_caracteristique\n",
    "            min_validation_erreur = validation_erreur\n",
    "        \n",
    "    x_dense = np.linspace(min(seuil_caracteristiques), max(seuil_caracteristiques), 500)  # 500 points pour une courbe lisse\n",
    "    spline = make_interp_spline(seuil_caracteristiques, erreur_for_seuil_caracteristiques)\n",
    "    y_dense = spline(x_dense)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "    plt.scatter(seuil_caracteristiques, erreur_for_seuil_caracteristiques, color='r')\n",
    "    plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "    plt.gca().xaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.xlim(0, max(seuil_caracteristiques))\n",
    "    plt.ylim(0, max(erreur_for_seuil_caracteristiques)+0.05)\n",
    "    plt.xlabel(f\"Seuil utilisé.\\nSi le % de mots dans l'intervalle [{index_left},{index_right}] est supérieure à ce seuil,\\nle texte sera attribué à Molière.\", fontsize=20)\n",
    "    plt.ylabel(f'Erreur pour distinguer des oeuvres de Molière et Corneille', fontsize=20)\n",
    "    plt.title(f\"Evolution de l'erreur en fonction du seuil choisi\\nCaractéristique utilisée: % de mots dans l'intervalle [{index_left},{index_right}]\", fontsize=20)\n",
    "    #plt.legend()\n",
    "    print(f'Min(error) = {min_validation_erreur} (seuil= {min_seuil_caracteristique})')\n",
    "        \n",
    "def display_vertical_line(plt, index, title:str, color:str) -> None:\n",
    "    label = f'{title}: {index+1:.0f}'\n",
    "    plt.axvline(index, color=color, linestyle='dashed', linewidth=1.5, label=label)\n",
    "    plt.text(index, plt.ylim()[1] * 0.7, label, color=color, rotation=90, verticalalignment='center', fontsize=20)\n",
    "\n",
    "def affiche_rapport_de_frequences(text:str, title:str, display_in_percentage: bool, display_left_rectangle:bool = False, display_right_rectangle:bool = False):\n",
    "    values, index_mean, meanV2, index_mode, index_Q1, index_Q2, index_Q3 = get_values_mean_mode_interquartiles_indexes(text)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    if display_in_percentage:\n",
    "        sum_elements = float(sum(map(abs, values)))\n",
    "        values = [ v /sum_elements for v in values]\n",
    "        \n",
    "    plt.bar(range(most_common_normalized_words_count), values, color='blue', tick_label=most_used_unnormalized_word)\n",
    "    # Add title and labels\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.xlabel('Mot', fontsize=15)\n",
    "    if display_in_percentage:\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        plt.ylabel(f\"Fréquence d'occurences\", fontsize=25)\n",
    "    else:\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel(f\"Nombre d'occurences\", fontsize=25)\n",
    "    plt.gca().tick_params(axis='y', which='major', labelsize=15) \n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    plt.xlim(-0.5, most_common_normalized_words_count - 0.5)\n",
    "    plt.ylim(-1, 1.1*max(values))\n",
    "    \n",
    "    \n",
    "    linewidth_rectangle = 1\n",
    "    fontsize_rectangle = 12\n",
    "    if display_left_rectangle: # Dessine un rectangle à gauche du diagramme de rapport de fréquences\n",
    "        min_rect = 0\n",
    "        max_rect = len(values)/2\n",
    "        plt.gca().add_patch(plt.Rectangle((min_rect-0.5, 0), max_rect, max(values), edgecolor='red',facecolor='none', linewidth=linewidth_rectangle, hatch='//'))\n",
    "        percentage_left = sum(values[0:len(values)//2])/sum(values)\n",
    "        plt.text(min_rect+0.5*(max_rect-min_rect), 1.05*max(values) , f\"{int(100*percentage_left)}% des mots à gauche du diagramme de rapport de fréquences (mots plus fréquents chez Molière)\", color='red', fontsize=fontsize_rectangle, ha='center', va='center')\n",
    "    if display_right_rectangle: # Dessine un rectangle à droite du diagramme de rapport de fréquences\n",
    "        min_rect = len(values)/2\n",
    "        max_rect = len(values)\n",
    "        plt.gca().add_patch(plt.Rectangle((min_rect-0.5, 0), max_rect, max(values), edgecolor='red',facecolor='none', linewidth=linewidth_rectangle, hatch='//'))\n",
    "        percentage_right = sum(values[len(values)//2:])/sum(values)\n",
    "        plt.text(min_rect+0.5*(max_rect-min_rect), 1.05*max(values) , f\"{int(100*percentage_right)}% des mots à droite du diagramme de rapport de fréquences (mots plus fréquents chez Corneille)\", color='red', fontsize=fontsize_rectangle, ha='center', va='center')\n",
    "\n",
    "    #display_vertical_line(plt, index_mean, title='Mean', color='purple')\n",
    "    #display_vertical_line(plt, index_mode, title='Mode', color='red')\n",
    "    #display_vertical_line(plt, index_Q1, title='Q1', color='green')\n",
    "    #display_vertical_line(plt, index_Q2, title='Median', color='green')\n",
    "    #display_vertical_line(plt, index_Q3, title='Q3', color='green')\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def get_random_extract(author_dataset) -> Tuple[str,str]:\n",
    "    name = random.choice(list(author_dataset.keys()))\n",
    "    idx =random.randint(0, len(author_dataset[name])-1)\n",
    "    comment = f'Extrait {idx+1}/{len(author_dataset[name])} de {name}'\n",
    "    return (comment, random.choice(author_dataset[name]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3baff9",
   "metadata": {},
   "source": [
    "## PRIVE: Chargement des données et création d'un fichier de statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd281715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# chargement des dataset complets associés à Molière et Corneille\n",
    "moliere_full_dataset = load_all_books(os.path.join(directory, 'moliere'))\n",
    "corneille_full_dataset = load_all_books(os.path.join(directory, 'corneille'))\n",
    "print(f'\\nMolière Dataset: {paragraph_count(moliere_full_dataset)} paragraphes ({word_count(moliere_full_dataset)} mots) venant de {len(moliere_full_dataset)} oeuvres:\\n{list(moliere_full_dataset.keys())}')\n",
    "print(f'\\nCorneille Dataset: {paragraph_count(corneille_full_dataset)} paragraphes ({word_count(corneille_full_dataset)} mots) venant de {len(corneille_full_dataset)} oeuvres:\\n{list(corneille_full_dataset.keys())}')\n",
    "\n",
    "\n",
    "# split des données entre train et validation\n",
    "moliere_train_dataset,moliere_validation_dataset,corneille_train_dataset,corneille_validation_dataset = split_train_validation_all_authors(moliere_full_dataset, corneille_full_dataset, percentage_in_train)\n",
    "print(f'\\nMolière Train Dataset: {paragraph_count(moliere_train_dataset)} paragraphes ({word_count(moliere_train_dataset)} mots) venant de {len(moliere_train_dataset)} oeuvres:\\n{list(moliere_train_dataset.keys())}')\n",
    "print(f'\\nMolière Validation Dataset: {paragraph_count(moliere_validation_dataset)} paragraphes ({word_count(moliere_validation_dataset)} mots) venant de {len(moliere_validation_dataset)} oeuvres:\\n{list(moliere_validation_dataset.keys())}')\n",
    "print(f'\\nCorneille Train Dataset: {paragraph_count(corneille_train_dataset)} paragraphes ({word_count(corneille_train_dataset)} mots) venant de {len(corneille_train_dataset)} oeuvres:\\n{list(corneille_train_dataset.keys())}')\n",
    "print(f'\\nCorneille Validation Dataset: {paragraph_count(corneille_validation_dataset)} paragraphes ({word_count(corneille_validation_dataset)} mots) venant de {len(corneille_validation_dataset)} oeuvres:\\n{list(corneille_validation_dataset.keys())}')\n",
    "\n",
    "    \n",
    "\n",
    "stats_moliere_train_dataset = compute_normalized_words_to_stats_without_stop_words(all_paragraphs(moliere_train_dataset))\n",
    "moliere_train_dataset_total_word_count = sum([c[0] for c in stats_moliere_train_dataset.values()])\n",
    "\n",
    "stats_corneille_train_dataset = compute_normalized_words_to_stats_without_stop_words(all_paragraphs(corneille_full_dataset))\n",
    "corneille_train_dataset_total_word_count = sum([c[0] for c in stats_corneille_train_dataset.values()])\n",
    "\n",
    "normalized_words = list((set(stats_moliere_train_dataset.keys())|set(stats_corneille_train_dataset.keys())))\n",
    "normalized_words.sort()\n",
    "moliere_frequency = []\n",
    "moliere_count = []\n",
    "corneille_frequency = []\n",
    "corneille_count = []\n",
    "\n",
    "\n",
    "for normalized_word in normalized_words:\n",
    "    if normalized_word in stats_moliere_train_dataset:\n",
    "        stat = stats_moliere_train_dataset[normalized_word]\n",
    "        moliere_frequency.append(stat[0]/moliere_train_dataset_total_word_count)\n",
    "        moliere_count.append(stat[0])\n",
    "    else:\n",
    "        moliere_frequency.append(0)\n",
    "        moliere_count.append(0)\n",
    "    if normalized_word in stats_corneille_train_dataset:\n",
    "        stat = stats_corneille_train_dataset[normalized_word]\n",
    "        corneille_frequency.append(stat[0]/corneille_train_dataset_total_word_count)\n",
    "        corneille_count.append(stat[0])\n",
    "    else:\n",
    "        corneille_frequency.append(0)\n",
    "        corneille_count.append(0)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'normalized_words': normalized_words,\n",
    "    'moliere_frequency': moliere_frequency,\n",
    "    'moliere_count': moliere_count,\n",
    "    'corneille_frequency' : corneille_frequency,\n",
    "    'corneille_count' : corneille_count,\n",
    "    })\n",
    "\n",
    "# on sauvegarde ces stats sur le disque\n",
    "df.to_csv(os.path.join(directory, 'stylometrie_stats.csv'), index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "def most_common_unnormalized_word(normalized_word: str) -> str:\n",
    "    res = dict()\n",
    "    if normalized_word in stats_moliere_train_dataset:\n",
    "        res = dict(stats_moliere_train_dataset[normalized_word][1])\n",
    "    if normalized_word in stats_corneille_train_dataset:\n",
    "        for w,count in stats_corneille_train_dataset[normalized_word][1].items():\n",
    "            if w in res:\n",
    "                res[w] += count\n",
    "            else:\n",
    "                res[w] = count\n",
    "    if len(res) == 0:\n",
    "        return ''\n",
    "    return max(res, key=res.get)\n",
    "\n",
    "df_top_words = df.copy()\n",
    "df_top_words['alpha'] = df_top_words.apply(lambda row: row['moliere_frequency'] / max(row['corneille_frequency'], 1e-9), axis=1)\n",
    "df_top_words['total_frequency'] = df_top_words['moliere_frequency']+df_top_words['corneille_frequency']\n",
    "df_top_words = df_top_words.sort_values(by='total_frequency', ascending=False)\n",
    "df_top_words = df_top_words.drop(columns=['total_frequency'])\n",
    "df_top_words = df_top_words.head(most_common_normalized_words_count)\n",
    "df_top_words = df_top_words.sort_values(by='alpha', ascending=False)\n",
    "df_top_words['unnormalized_word'] = df_top_words['normalized_words'].apply(most_common_unnormalized_word)\n",
    "\n",
    "df_top_words.to_csv(os.path.join(directory, 'stylometrie_stats_top_words.csv'), index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "most_used_words = list(df_top_words['normalized_words'])\n",
    "most_used_unnormalized_word = list(df_top_words['unnormalized_word'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e0de2",
   "metadata": {},
   "source": [
    "# PRIVE: outil de recherche de textes très spécifiques à Molière ou Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words_moliere = sum([c[0] for c in stats_moliere_train_dataset.values()])\n",
    "total_words_corneille = sum([c[0] for c in stats_corneille_train_dataset.values()])\n",
    "\n",
    "\n",
    "def compute_word_score_moliere_vs_corneille(count_moliere:int, count_corneille:int):\n",
    "    if count_moliere+count_corneille<30:\n",
    "        return 0\n",
    "    if count_moliere == 0:\n",
    "        return -1\n",
    "    if count_corneille == 0:\n",
    "        return 1\n",
    "    percentage_moliere = count_moliere/total_words_moliere\n",
    "    percentage_corneille = count_corneille/total_words_corneille\n",
    "    if percentage_moliere>2*percentage_corneille:\n",
    "        return 1\n",
    "    if percentage_corneille>2*percentage_moliere:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def to_string_percentage(count:int, total_count:int):\n",
    "    if total_count<=0:\n",
    "        return \"0%\"\n",
    "    percentage = count/total_count\n",
    "    return f\"{round(100*percentage,3)}%\"\n",
    "\n",
    "def find_most_distinctive_lines(is_moliere: bool) -> None:\n",
    "    min_score_moliere = 0\n",
    "    max_score_moliere = 0\n",
    "    set_most_used_words = set(most_used_words)\n",
    "    \n",
    "    author_dataset = moliere_full_dataset  if is_moliere else corneille_full_dataset\n",
    "    \n",
    "    for book_name, paragraphs in author_dataset.items():\n",
    "        for paragraph in paragraphs:\n",
    "            for line in paragraph.splitlines():\n",
    "                words = set(split_text(line))\n",
    "                if len(words)<5:\n",
    "                    continue\n",
    "                line_score_moliere_vs_corneille = 0\n",
    "                comment_moliere = \"\"\n",
    "                comment_corneille = \"\"\n",
    "                for original_word in words:\n",
    "                    normalized_word = compute_normalized_word(original_word)\n",
    "                    if normalized_word not in set_most_used_words:\n",
    "                        continue\n",
    "                    count_moliere = stats_moliere_train_dataset[normalized_word][0] if normalized_word in stats_moliere_train_dataset else 0\n",
    "                    count_corneille = stats_corneille_train_dataset[normalized_word][0] if normalized_word in stats_corneille_train_dataset else 0\n",
    "                    word_score_moliere_vs_corneille = compute_word_score_moliere_vs_corneille(count_moliere, count_corneille)\n",
    "                    if word_score_moliere_vs_corneille == 0:\n",
    "                        continue\n",
    "                    percent_moliere = to_string_percentage(count_moliere, total_words_moliere)\n",
    "                    percent_corneille = to_string_percentage(count_corneille, total_words_corneille)\n",
    "                    if is_moliere:\n",
    "                        comment = f\"{original_word} ({percent_moliere} vs {percent_corneille}) \"\n",
    "                    else:\n",
    "                        comment = f\"{original_word} ({percent_corneille} vs {percent_moliere}) \"\n",
    "                    if word_score_moliere_vs_corneille>0:\n",
    "                        comment_moliere += comment\n",
    "                    else:\n",
    "                        comment_corneille += comment\n",
    "                    line_score_moliere_vs_corneille += word_score_moliere_vs_corneille\n",
    "                if is_moliere and comment_corneille:\n",
    "                    continue\n",
    "                if not is_moliere and comment_moliere:\n",
    "                    continue\n",
    "                if abs(line_score_moliere_vs_corneille)>=2 and (len(comment_moliere)==0 or len(comment_corneille)==0):\n",
    "                #if total_score_moliere<min_score_moliere or line_score_moliere_vs_corneille>max_score_moliere:\n",
    "                    min_score_moliere = min(min_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    max_score_moliere = max(max_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    print('-'*50)\n",
    "                    print(f\"Oeuvre de {'Molière' if is_moliere else 'Corneille'}: {book_name}\")\n",
    "                    print(line)\n",
    "                    print(f'Score: {line_score_moliere_vs_corneille}')\n",
    "                    if comment_moliere:\n",
    "                        print(f'avantage Molière: {comment_moliere}')\n",
    "                    if comment_corneille:\n",
    "                        print(f'avantage Corneille: {comment_corneille}')\n",
    "                    print('-'*50)\n",
    "                    print()\n",
    "\n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Molière')\n",
    "find_most_distinctive_lines(True)\n",
    "print()\n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Corneille')\n",
    "#find_most_distinctive_lines(False)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f14360",
   "metadata": {},
   "source": [
    "#  Mise en situation:\n",
    "## On veut identifier les auteurs des 2 phrases suivantes:\n",
    "### - Ah ! ah ! vous voilà. Je suis ravi de vous trouver, Monsieur le coquin.\n",
    "### - Tes rares qualités te font d'un autre sang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3884dc",
   "metadata": {},
   "source": [
    "## On montre les fréquences d'apparition de certains mots chez Molière et Corneille "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2c94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_table_with_occurences_corneille_moliere(original_words: List[str]) -> pd.DataFrame:\n",
    "\n",
    "    original_words.sort()\n",
    "    occurences_moliere = []\n",
    "    occurences_corneille = []\n",
    "    frequence_moliere = []\n",
    "    frequence_corneille = []\n",
    "    for original_word in original_words:\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        occurences_moliere.append(stats_moliere_train_dataset[normalized_word][0] if normalized_word in stats_moliere_train_dataset else 0)\n",
    "        occurences_corneille.append(stats_corneille_train_dataset[normalized_word][0] if normalized_word in stats_corneille_train_dataset else 0)\n",
    "        frequence_moliere.append(stats_moliere_train_dataset[normalized_word][0]/total_words_moliere if normalized_word in stats_moliere_train_dataset else 0)\n",
    "        frequence_corneille.append(stats_corneille_train_dataset[normalized_word][0]/total_words_corneille if normalized_word in stats_corneille_train_dataset else 0)\n",
    "    df =pd.DataFrame(\n",
    "        {'Mot': original_words,\n",
    "        'Occurences Molière': occurences_moliere,\n",
    "        'Occurences Corneille': occurences_corneille,\n",
    "        'Fréquence Molière': frequence_moliere,\n",
    "        'Fréquence Corneille': frequence_corneille} \n",
    "        )\n",
    "    df.set_index(['Mot'],inplace=True)    \n",
    "    return df   \n",
    "\n",
    "\n",
    "\n",
    "mots = ['ah', 'monsieur', 'voila', 'tes', 'rares', 'sang']\n",
    "\n",
    "df = create_table_with_occurences_corneille_moliere(mots)\n",
    "\n",
    "def format_percentage(value):\n",
    "    return f'{round(100*value,3)}%'\n",
    "# Exemple de fonction toto\n",
    "def create_comment(percent_moliere, percent_corneille):\n",
    "    if percent_corneille<=0:\n",
    "        return \"Mot présent uniquement chez Molière\"\n",
    "    if percent_moliere<=0:\n",
    "        return \"Mot présent uniquement chez Corneille\"\n",
    "    if percent_moliere>percent_corneille:\n",
    "        return f\"Mot {int(round(percent_moliere/percent_corneille,0))} fois plus utilisé chez Molière\"\n",
    "    else:\n",
    "        return f\"Mot {int(round(percent_corneille/percent_moliere,0))} fois plus utilisé chez Corneille\"\n",
    "\n",
    "# Création de la colonne C en appliquant la méthode toto\n",
    "df['Commentaire'] = df.apply(lambda row: create_comment(row['Fréquence Molière'], row['Fréquence Corneille']), axis=1)\n",
    "df['Fréquence chez Molière'] = df['Fréquence Molière'].apply(format_percentage)\n",
    "df['Fréquence chez Corneille'] = df['Fréquence Corneille'].apply(format_percentage)\n",
    "df[['Fréquence chez Molière', 'Fréquence chez Corneille', 'Commentaire']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01770f7b",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Ah ! ah ! vous voilà. Je suis ravi de vous trouver, Monsieur le coquin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cf813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46339da9",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Tes rares qualités te font d'un autre sang.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728399df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4de1e5",
   "metadata": {},
   "source": [
    "# On affiche le diagramme de rapport de fréquences de toutes les oeuvres de Molière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb613cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, extracts in moliere_full_dataset.items():\n",
    "    affiche_rapport_de_frequences(' '.join(extracts), \"oeuvre de Molière : \"+name, display_in_percentage = False, display_left_rectangle=True, display_right_rectangle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d7dd0",
   "metadata": {},
   "source": [
    "# On affiche le diagramme de rapport de fréquences de toutes les oeuvres de Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850129d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, extracts in corneille_full_dataset.items():\n",
    "    affiche_rapport_de_frequences(' '.join(extracts), \"oeuvre de Corneille : \"+name, display_in_percentage = False, display_left_rectangle=False, display_right_rectangle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8112d8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">1ère partie: </span><span style=\"font-size: 36px;\">(basée sur 1 caractéristique)</span><br><br>\n",
    "<span style=\"font-size: 36px;\">Déterminer si un texte a été écrit par Molière ou par Corneille, en se basant sur le % de mots dans un intervalle à gauche du diagramme de rapport de fréquences.</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 24px;\"><u>Méthode utilisée:</u></span><br>\n",
    "<span style=\"font-size: 24px;\">1. On recherche les 100 mots les plus différenciants entre Molière et Corneille</span><br>\n",
    "<span style=\"font-size: 24px;\">2. On trie ces 100 mot de celui qui est très fréquent chez Molière (et rare chez Corneille), à celui qui est très fréquent chez Corneille (et rare chez Molière)</span><br>\n",
    "<span style=\"font-size: 24px;\">3. Pour un texte donné, on extrait les mots de ce texte figurant dans les 100 mots les plus diférenciants, et on les place dans un diagramme de rapport de fréquences</span><br>\n",
    "<span style=\"font-size: 24px;\">4. On calcule le pourcentage de mots dans un intervalle à gauche du diagramme de rapport de fréquences (donc parmi les mots plus fréquents chez Molière que chez Corneille)</span><br>\n",
    "<span style=\"font-size: 24px;\">5. Si cette valeur est supérieure à un seuil, on attribue le texte à Molière, sinon à Corneille.</span><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841b52",
   "metadata": {},
   "source": [
    "### On affiche à l'étudiant la valeur de l'erreur pour différentes valeurs du seuil associé au % de mots dans l'intervalle [0, 49] du diagramme de rapport de fréquences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8d08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_left = 0\n",
    "index_right  = 49\n",
    "\n",
    "affiche_erreur_1_caracteristique(index_left, index_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65bc40",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# la caractéristique à améliorer\n",
    "# ce '50' sera modifié par l'étudiant\n",
    "seuil_1ere_caracteristique = 50\n",
    "validation_erreur = calcul_validation_erreur_moliere_vs_corneille_1_caracteristique(index_left, index_right, seuil_1ere_caracteristique)\n",
    "print(f'Erreur(Molière ou Corneille?)= {round(100*validation_erreur,1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7bf40",
   "metadata": {},
   "source": [
    "### On affiche à l'étudiant la valeur de l'erreur pour différentes valeurs du seuil associé au % de mots dans l'intervalle [0, 19] du diagramme de rapport de fréquences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_left = 0\n",
    "index_right  = 19\n",
    "affiche_erreur_1_caracteristique(index_left, index_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf346fa",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# la caractéristique à améliorer\n",
    "# ce '50' sera modifié par l'étudiant\n",
    "seuil_1ere_caracteristique = 50\n",
    "validation_erreur = calcul_validation_erreur_moliere_vs_corneille_1_caracteristique(index_left, index_right, seuil_1ere_caracteristique)\n",
    "print(f'Erreur(Molière ou Corneille?)= {round(100*validation_erreur,1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeabbc9",
   "metadata": {},
   "source": [
    "# Utilisation de 2 caractéristiques:\n",
    "## % de mots dans un intervalle à gauche du diagramme de rapport de fréquences Molière/Corneille et\n",
    "## % de mots dans un autre intervalle à droite du diagramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bc331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def valeur_2_caracteristiques(text:str, index_left_caracteristique1:int, index_right_caracteristique1:int, index_left_caracteristique2:int, index_right_caracteristique2:int) -> Tuple[float,float]:\n",
    "    values = compute_words_count_in_text(text)\n",
    "    valeur_caracteristique1 =  100*sum(values[index_left_caracteristique1: index_right_caracteristique1+1])/max(1,sum(values))\n",
    "    valeur_caracteristique2 =  100*sum(values[index_left_caracteristique2: index_right_caracteristique2+1])/max(1,sum(values))\n",
    "    return valeur_caracteristique1,valeur_caracteristique2\n",
    "\n",
    "\n",
    "def display_2D(text_moliere: List[str], text_corneille: List[str], index_left_caracteristique1:int, index_right_caracteristique1:int, index_left_caracteristique2:int, index_right_caracteristique2:int, seuil_pente:float = None, seuil_ordonnee_a_l_origine:float = None) -> None:\n",
    "    x_moliere = []\n",
    "    y_moliere = []\n",
    "    for t in text_moliere:\n",
    "        valeur_caracteristique1,valeur_caracteristique2 = valeur_2_caracteristiques(t, index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2)\n",
    "        x_moliere.append(valeur_caracteristique2)\n",
    "        y_moliere.append(valeur_caracteristique1)\n",
    "    x_corneille = []\n",
    "    y_corneille = []\n",
    "    for t in text_corneille:\n",
    "        valeur_caracteristique1,valeur_caracteristique2 = valeur_2_caracteristiques(t, index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2)\n",
    "        x_corneille.append(valeur_caracteristique2)\n",
    "        y_corneille.append(valeur_caracteristique1)\n",
    "\n",
    "    # Dessiner les points\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    size = 10\n",
    "    plt.scatter(x_moliere, y_moliere, color='green', label='Oeuvre de Molière', s=size)\n",
    "    plt.scatter(x_corneille, y_corneille, color='red', label='Oeuvre de Corneille', s=size)\n",
    "\n",
    "    # Ajouter des détails au graphique\n",
    "    plt.title('')\n",
    "    plt.xlabel(f\"Valeur de la 2ème caratéristique\\n% de mots dans l'intervalle [{index_left_caracteristique2},{index_right_caracteristique2}]\", fontsize=12)\n",
    "    plt.ylabel(f\"Valeur de la 1ère caratéristique\\n% de mots dans l'intervalle [{index_left_caracteristique1},{index_right_caracteristique1}]\", fontsize=12)\n",
    "    \n",
    "    x_lim = max(max(x_moliere),max(x_corneille))\n",
    "    y_lim = max(max(y_moliere),max(y_corneille))\n",
    "    \n",
    "    \n",
    "    if seuil_pente and seuil_ordonnee_a_l_origine:\n",
    "        # Draw the line using a point and the slope\n",
    "        plt.axline((0, seuil_ordonnee_a_l_origine), slope=seuil_pente, color='blue', label=f'f(x) = {seuil_pente}x + {seuil_ordonnee_a_l_origine}')\n",
    "    \n",
    "    plt.xlim(0, max(x_lim,y_lim))\n",
    "    plt.ylim(0, max(x_lim,y_lim))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def is_moliere_2_caracteristiques(t : str, index_left_caracteristique1:int, index_right_caracteristique1:int, index_left_caracteristique2:int, index_right_caracteristique2:int, seuil_pente:float, seuil_ordonnee_a_l_origine:float):\n",
    "    valeur_caracteristique1,valeur_caracteristique2 = valeur_2_caracteristiques(t, index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2)\n",
    "    y = seuil_pente * valeur_caracteristique2 + seuil_ordonnee_a_l_origine\n",
    "    return valeur_caracteristique1>y\n",
    "\n",
    "\n",
    "def calcul_confusion_matrix_2_caracteristiques(text_moliere: List[str], text_corneille: List[str], index_left_caracteristique1:int, index_right_caracteristique1:int, index_left_caracteristique2:int, index_right_caracteristique2:int, seuil_pente:float, seuil_ordonne_a_l_oirigne:float) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = Molière ,  y_pred = Molière\n",
    "    TN = 0 # y_true = Corneille, y_pred = Corneille\n",
    "    FN = 0 # y_true = Molière,   y_pred = Corneille\n",
    "    FP = 0 # y_true = Corneille, y_pred = Molière \n",
    "    for t in text_moliere:\n",
    "        if is_moliere_2_caracteristiques(t, index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2, seuil_pente, seuil_ordonnee_a_l_origine):\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    for t in text_corneille:\n",
    "        if is_moliere_2_caracteristiques(t, index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2, seuil_pente, seuil_ordonnee_a_l_origine):\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "    \n",
    "def calcul_validation_erreur_moliere_vs_corneille_2_caracteristiques(index_left_caracteristique1:int, index_right_caracteristique1:int, index_left_caracteristique2:int, index_right_caracteristique2:int, seuil_pente:float, seuil_ordonnee_a_l_origine:float) -> float:\n",
    "    return calcul_erreur(*calcul_confusion_matrix_2_caracteristiques(all_paragraphs(moliere_validation_dataset), all_paragraphs(corneille_validation_dataset), index_left_caracteristique1, index_right_caracteristique1, index_left_caracteristique2, index_right_caracteristique2, seuil_pente, seuil_ordonnee_a_l_origine))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Intervalle associé à la 1ère caractéristique.\n",
    "# La valeur de la 1ère caractéristique sera le % de mot dans cet intervalle\n",
    "left_index_caracteristique1 = 0\n",
    "right_index_caracteristique1 = 12\n",
    "\n",
    "# Intervalle associé à la 2ème caractéristique.\n",
    "# La valeur de la 2ème caractéristique sera le % de mot dans cet intervalle\n",
    "left_index_caracteristique2 = 89\n",
    "right_index_caracteristique2 =99\n",
    "\n",
    "# droite permettant de séparer le plan en 2: \n",
    "# - les points au dessus de cette droite seront attribués à Molière, les autres à Corneille\n",
    "seuil_pente = 0.6\n",
    "seuil_ordonnee_a_l_origine = 5.5\n",
    "\n",
    "\n",
    "display_2D(all_paragraphs(moliere_validation_dataset), all_paragraphs(corneille_validation_dataset), left_index_caracteristique1,right_index_caracteristique1,left_index_caracteristique2,right_index_caracteristique2, seuil_pente=seuil_pente, seuil_ordonnee_a_l_origine=seuil_ordonnee_a_l_origine)\n",
    "validation_erreur = calcul_validation_erreur_moliere_vs_corneille_2_caracteristiques(left_index_caracteristique1,right_index_caracteristique1,left_index_caracteristique2,right_index_caracteristique2, seuil_pente=seuil_pente, seuil_ordonnee_a_l_origine=seuil_ordonnee_a_l_origine)\n",
    "    \n",
    "print(f'Erreur(Molière ou Corneille?)= {round(100*validation_erreur,2)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896108d1",
   "metadata": {},
   "source": [
    "# Hyperparameters Search (disabled by default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "import time \n",
    "text = f'seuil_pente,seuil_ordonnee_a_l_origine,left_index_caracteristique1,right_index_caracteristique1,left_index_caracteristique2,right_index_caracteristique2,total_points_caracteristique1,total_points_caracteristique2,erreur\\n'\n",
    "filename = 'c:/temp/hpo_'+str(int(time.time()))+'.csv'\n",
    "\n",
    "for left_index_caracteristique1 in [0]:\n",
    "    for right_index_caracteristique2 in [most_common_normalized_words_count-1]:\n",
    "        for total_points_caracteristique1 in range(10,30+1,1):\n",
    "            for total_points_caracteristique2 in range(10,30+1,1):\n",
    "                for seuil_pente in np.arange(0.6, 1.0, 0.05):\n",
    "                    for seuil_ordonnee_a_l_origine in np.arange(0, 8, 0.5):\n",
    "                        right_index_caracteristique1 = left_index_caracteristique1+total_points_caracteristique1-1\n",
    "                        left_index_caracteristique2 = right_index_caracteristique2-total_points_caracteristique2+1\n",
    "                        validation_erreur = calcul_validation_erreur_moliere_vs_corneille_2_caracteristiques(left_index_caracteristique1,right_index_caracteristique1,left_index_caracteristique2,right_index_caracteristique2, seuil_pente=seuil_pente, seuil_ordonnee_a_l_origine=seuil_ordonnee_a_l_origine)\n",
    "                        text += f\"{seuil_pente},{seuil_ordonnee_a_l_origine},{left_index_caracteristique1},{right_index_caracteristique1},{left_index_caracteristique2},{right_index_caracteristique2},{total_points_caracteristique1},{total_points_caracteristique2},{validation_erreur}\\n\"\n",
    "                        with open(filename, 'a') as f:\n",
    "                            f.write(text)\n",
    "                        text = ''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
