{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fab4cd",
   "metadata": {},
   "source": [
    "# Le but de ce notebook est d'identifier des caractéristiques permettant de différencier des textes écrits par Molière et Corneille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aecb3f",
   "metadata": {},
   "source": [
    "# PRIVE: Hyperparamétres fixés par MathAData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da83bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de caractéres dans chaque paragraphe dont on veut identifier l'auteur\n",
    "# 1000 caractéres correspond à environ une page de texte (environ 180 mots)\n",
    "min_paragraph_length = 1000\n",
    "\n",
    "# on divisie les données d'entraînement en 90% en train et 10% en validation\n",
    "# une oeuvre doit être entièrement soit en train soit en validation\n",
    "percentage_in_train = 0.9\n",
    "\n",
    "# on ignore les majuscules / minuscules dans les mots: Monsieur == monsieur\n",
    "use_lowercase = True\n",
    "\n",
    "# on ignore les accents:  être == etre\n",
    "use_diacritics = True\n",
    "\n",
    "# cette option permet de ne tenir compte que de la racine du mot.\n",
    "# elle est désactivée car elle dégrade nettement les performances\n",
    "use_stemming = False\n",
    "\n",
    "# nombre de mots signatures chez chaque auteur\n",
    "# on ne regarde que les 'most_common_normalized_words_count' mots les plus courants chez chaque auteur\n",
    "most_common_normalized_words_count = 50\n",
    "\n",
    "# Mots vides. \n",
    "# Ils sont ignorés par l'outil car très communs à la fois chez Molière et chez Corneille\n",
    "stop_words = set([\"de\",\"et\",\"que\",\"je\",\"a\",\"la\",\"le\",\"ne\",\"ce\",\"il\",\"pour\",\"un\",\"qui\",\"me\",\"est\",\"mais\",\"des\",\"moi\",\"votre\",\"qu'il\",\"lui\",\"du\",\"fait\",\"par\",\"se\",\"au\",\"cette\",\"sur\",\"j'ai\",\"avec\",\"tous\",\"vos\",\"ces\",\"n'est\",\"peu\",\"peut\",\"quelque\",\"dont\",\"quoi\",\"aux\",\"donc\",\"d'une\",\"s'il\",\"notre\",\"sais\",\"donne\",\"vois\",\"m'en\",\"cet\",\"autre\",\"puis\",\"assez\",\"quel\",\"veut\",\"va\",\"ils\",\"doit\",\"ont\",\"vu\", \"en\", \"les\", \"vous\", \"mon\",\"pas\",\"si\",\"plus\", \"tout\", \"nous\", \"ma\", \"sans\", \"ou\", \"c'est\", \"bien\", \"dans\",\"une\", \"son\",\"tu\", \"point\", \"mais\", \"mes\", \"d'un\", \"elle\", \"ses\", \"meme\", \"comme\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82185316",
   "metadata": {},
   "source": [
    "# PRIVE: Méthodes utilisés dans le Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09dcc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import List,Set,Tuple,Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "#!pip install unidecode\n",
    "#!pip install wordcloud\n",
    "#!pip install pillow\n",
    "\n",
    "\n",
    "# le répertoire de travail\n",
    "directory = os.path.abspath('')\n",
    "random.seed(42)\n",
    "\n",
    "# retourne tous les fichiers *.txt présents dans le repertoire 'path'\n",
    "def all_txt_files_in_directory(path: str):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.txt')]\n",
    "\n",
    "# infique si la ligne 'ligne' est une ligne valide ou si elle doit être ignorée (par exemple si elle vide)\n",
    "def is_valid_line(line: str) -> bool:\n",
    "    if line.startswith('Scène ') or line.startswith('Acte '):\n",
    "        return False\n",
    "    if len(line)<10:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def split_book_into_paragraphs(path: str) -> List[str]:\n",
    "    result = []\n",
    "    with open(path) as file:\n",
    "        current_paragraph = \"\"\n",
    "        for line in file:\n",
    "            if is_valid_line(line):\n",
    "                if current_paragraph :\n",
    "                    current_paragraph += \"\\n\"\n",
    "                current_paragraph += line.rstrip()\n",
    "                if len(current_paragraph) >= min_paragraph_length:\n",
    "                    result.append(current_paragraph) \n",
    "                    current_paragraph = \"\"\n",
    "    if len(current_paragraph) >= min_paragraph_length or (current_paragraph and len(result) == 0):\n",
    "        result.append(current_paragraph) \n",
    "    return result\n",
    "\n",
    "def load_all_books(path: str) -> Dict[str,List[str]]:\n",
    "    book_to_paragraphs = dict()\n",
    "    for book_path in all_txt_files_in_directory(path):\n",
    "        book_to_paragraphs[pathlib.Path(book_path).stem] = split_book_into_paragraphs(book_path)\n",
    "    return book_to_paragraphs\n",
    "\n",
    "# pour supprimer les accents\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def remove_diacritics(word: str) -> str:\n",
    "    import unidecode  \n",
    "    return unidecode.unidecode(word)\n",
    "\n",
    "# mots en minuscules\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def to_lowercase(word: str) -> str:\n",
    "    return word.lower()\n",
    "\n",
    "# pour le stemming\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def to_stemming(word: str) -> str:\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_normalized_word(word: str) -> str:\n",
    "    if use_lowercase:\n",
    "        word = to_lowercase(word)\n",
    "    if use_diacritics:\n",
    "        word = remove_diacritics(word)\n",
    "    if use_stemming:\n",
    "        word = to_stemming(word)\n",
    "    return word\n",
    "\n",
    "def paragraph_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    if not book_to_paragraphs:\n",
    "        return 0\n",
    "    return sum([len(c) for c in book_to_paragraphs.values()])\n",
    "\n",
    "def split_text(text:str) -> List[str]:\n",
    "    return re.findall(r\"\\b[\\w'^\\d]+\\b\", text.rstrip())\n",
    "            \n",
    "def word_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    result = 0\n",
    "    for paragraph in all_paragraphs(book_to_paragraphs):\n",
    "        result += len(split_text(paragraph.rstrip()))\n",
    "    return result\n",
    "\n",
    "def all_paragraphs(book_to_paragraphs: Dict[str, List[str]]) -> List[str]:\n",
    "    result = []\n",
    "    for p in book_to_paragraphs.values():\n",
    "        result.extend(p)\n",
    "    return result\n",
    "\n",
    "# reduce the dataset so that it contains exactly 'target_count' paragraphs\n",
    "def reduce_to_paragraph_count(book_to_paragraphs: dict, target_count: int ) -> int:\n",
    "    current_count = paragraph_count(book_to_paragraphs)\n",
    "    if current_count<target_count:\n",
    "        raise Exception(f'current_count {current_count} < target_count {target_count}')\n",
    "    to_remove = current_count-  target_count\n",
    "    result = dict()\n",
    "    for book, paragraphs in sorted(book_to_paragraphs.items(), key =lambda x : len(x[1])):\n",
    "        if len(paragraphs)<=to_remove:\n",
    "            to_remove-=len(paragraphs)\n",
    "            continue\n",
    "        result[book] = paragraphs[:len(paragraphs)-to_remove]\n",
    "        to_remove = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_most_common_normalized_words(normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], most_common_count:int) -> Dict[str,float]:\n",
    "    sorted_by_total_count = sorted(normalized_words_to_stats.items(), key=lambda item:item[1][0], reverse=True)\n",
    "    total_count = sum([stats[0] for normalized_word,stats in normalized_words_to_stats.items() if normalized_word not in stop_words])\n",
    "    result  = dict()\n",
    "    for normalized_word,stats in sorted_by_total_count:\n",
    "        if normalized_word not in stop_words:\n",
    "            result[normalized_word] = stats[0]/total_count\n",
    "        if len(result)>=most_common_count:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def compute_normalized_words_to_stats(paragraphs: List[str]) -> Dict[str, Tuple[int,Dict[str,int]] ]:\n",
    "    normalized_words_to_stats = dict()\n",
    "    for paragraph in paragraphs:\n",
    "        words = split_text(paragraph)\n",
    "        for original_word in words:\n",
    "            normalized_word = compute_normalized_word(original_word)\n",
    "            if normalized_word not in normalized_words_to_stats:\n",
    "                normalized_words_to_stats[normalized_word] = (0, dict())\n",
    "            count,original_word_count = normalized_words_to_stats[normalized_word]\n",
    "            if original_word not in original_word_count:\n",
    "                original_word_count[original_word] = 1\n",
    "            else:\n",
    "                original_word_count[original_word] += 1\n",
    "            normalized_words_to_stats[normalized_word] = (count+1,original_word_count)\n",
    "    return normalized_words_to_stats\n",
    "\n",
    "def compute_normalized_word_to_original_word(text: str) -> Dict[str,str]:\n",
    "    normalized_word_to_original_word = dict()\n",
    "    splitted_text = split_text(text)\n",
    "    for original_word in splitted_text:\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in stop_words:\n",
    "            continue\n",
    "        normalized_word_to_original_word[normalized_word] = original_word\n",
    "    return normalized_word_to_original_word\n",
    "\n",
    "def get_max_item(dic: Dict[str, int]) -> Tuple[str,int]:\n",
    "    key_max_count, max_count = (None, None)\n",
    "    for key,count in dic.items():\n",
    "        if max_count is None or count > max_count:\n",
    "            key_max_count, max_count = key, count\n",
    "    return key_max_count, max_count\n",
    "    \n",
    "def split_train_validation_single_author(book_to_paragraphs: dict, percentage_in_train:float) :\n",
    "    books = list(book_to_paragraphs.keys())\n",
    "    train = dict()\n",
    "    validation = dict()\n",
    "    for book, paragraphs in book_to_paragraphs.items():\n",
    "        paragraphs_count = len(paragraphs)\n",
    "        percentage_in_train_if_adding_to_train = (paragraph_count(train)+len(paragraphs))/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        percentage_in_train_if_adding_to_validation = paragraph_count(train)/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        if abs(percentage_in_train_if_adding_to_train-percentage_in_train)<abs(percentage_in_train_if_adding_to_validation-percentage_in_train):\n",
    "            train[book] = paragraphs\n",
    "        else:\n",
    "            validation[book] = paragraphs\n",
    "    return train, validation\n",
    "\n",
    "def split_train_validation_all_authors(book_to_paragraphs_author1: dict, book_to_paragraphs_author2: dict, percentage_in_train:float) :\n",
    "    train_author1,validation_author1 = split_train_validation_single_author(book_to_paragraphs_author1, percentage_in_train)\n",
    "    train_author2,validation_author2 = split_train_validation_single_author(book_to_paragraphs_author2, percentage_in_train)\n",
    "\n",
    "    target_length_validation = min(paragraph_count(validation_author1),paragraph_count(validation_author2))            \n",
    "    validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "    validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "\n",
    "    target_length_train = min(paragraph_count(train_author1),paragraph_count(train_author2))            \n",
    "    train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "    train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "\n",
    "    proportion_in_train = target_length_train/(target_length_train+target_length_validation)\n",
    "    if proportion_in_train>percentage_in_train:\n",
    "        target_length_train = int( (percentage_in_train/(1-percentage_in_train)) *target_length_validation )\n",
    "        train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "        train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "    else:\n",
    "        target_length_validation = int( ((1-percentage_in_train)/percentage_in_train) *target_length_train )\n",
    "        validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "        validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "    return train_author1,validation_author1,train_author2,validation_author2\n",
    "\n",
    "def calcul_accuracy(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (TP+TN)/max(TP+TN+FP+FN,1)\n",
    "\n",
    "def calcul_accuracy_corneille(TP: int, TN: int, FP: int, FN: int):\n",
    "    return TN/max(TN+FP,1)\n",
    "\n",
    "def calcul_accuracy_moliere(TP: int, TN: int, FP: int, FN: int):\n",
    "    return TP/max(TP+FN,1)\n",
    "\n",
    "def calcul_accuracy(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (TP+TN)/max(TP+TN+FP+FN,1)\n",
    "\n",
    "def compute_author_score(text:str, most_common_words_for_author: Dict[str,float]) -> float:\n",
    "    score = 0\n",
    "    for original_word in split_text(text):\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in most_common_words_for_author:\n",
    "            score += 1\n",
    "    return score\n",
    "\n",
    "def compute_confusion_matrix_single_author(author_name:str, texts_from_author: List[str], text_from_other_authors: List[str], most_common_words_from_author: dict , threshold_author_score: int, verbose:bool) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = author_name ,  y_pred = author_name\n",
    "    TN = 0 # y_true = another author, y_pred = another author\n",
    "    FN = 0 # y_true = author_name,   y_pred = another author\n",
    "    FP = 0 # y_true = another_author, y_pred = author_name \n",
    "    for t in texts_from_author:\n",
    "        score_author = compute_author_score(t, most_common_words_from_author)\n",
    "        if score_author>=threshold_author_score:\n",
    "            if TP == 0 and verbose:\n",
    "                print(f'\\nExemple de TP (Texte de {author_name}, bien identifié, score {author_name}: {round(score_author,4)}):\\n{t}\\n')\n",
    "            TP += 1\n",
    "        else:\n",
    "            if FN == 0 and verbose:\n",
    "                print(f'\\nExemple de FN (Texte de {author_name}, mal identifié, score {author_name}: {round(score_author,4)}):\\n{t}\\n')\n",
    "            FN += 1\n",
    "    for t in text_from_other_authors:\n",
    "        score_author = compute_author_score(t, most_common_words_from_author)\n",
    "        if score_author>=threshold_author_score:\n",
    "            if FP == 0 and verbose:\n",
    "                print(f\"\\nExemple de FP (Texte d'un autre auteur, mal identifié, score {score_author}: {round(score_author,4)}):\\n{t}\\n\")\n",
    "            FP += 1\n",
    "        else:\n",
    "            if TN == 0 and verbose:\n",
    "                print(f\"\\nExemple de TN (Texte d'un autre auteur, bien identifié, score {score_author}: {round(score_author,4)}):\\n{t}\\n\")\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "def train_single_author(author_dataset, author_name, other_authors_dataset, threshold_author_score: int, verbose: bool = False) -> Tuple[int,int,int,int]:\n",
    "    random.seed(42)\n",
    "    if verbose: \n",
    "        print(f'\\n{author_name} Dataset: {paragraph_count(author_dataset)} paragraphes ({word_count(author_dataset)} mots) venant de {len(author_dataset)} oeuvres:\\n{list(author_dataset.keys())}')\n",
    "        print(f'\\nother_authors Dataset: {paragraph_count(other_authors_dataset)} paragraphes ({word_count(other_authors_dataset)} mots) venant de {len(other_authors_dataset)} oeuvres:\\n{list(other_authors_dataset.keys())}')\n",
    "\n",
    "    train_author,validation_author,train_other_authors,validation_other_authors = split_train_validation_all_authors(author_dataset, other_authors_dataset, percentage_in_train)\n",
    "\n",
    "    if verbose: \n",
    "        print(f'\\n{author_name} Train Dataset: {paragraph_count(train_author)} paragraphes ({word_count(train_author)} mots) venant de {len(train_author)} oeuvres:\\n{list(train_author.keys())}')\n",
    "        print(f'\\n{author_name} Validation Dataset: {paragraph_count(validation_author)} paragraphes ({word_count(validation_author)} mots) venant de {len(validation_author)} oeuvres:\\n{list(validation_author.keys())}')\n",
    "        print(f'\\nother_authors Train Dataset: {paragraph_count(train_other_authors)} paragraphes ({word_count(train_other_authors)} mots) venant de {len(train_other_authors)} oeuvres:\\n{list(train_other_authors.keys())}')\n",
    "        print(f'\\nother_authors Validation Dataset: {paragraph_count(validation_other_authors)} paragraphes ({word_count(validation_other_authors)} mots) venant de {len(validation_other_authors)} oeuvres:\\n{list(validation_other_authors.keys())}')\n",
    "\n",
    "    train_normalized_words_to_stats_author = compute_normalized_words_to_stats(all_paragraphs(train_author))\n",
    "    # we only keep the most common words\n",
    "    train_most_common_author = compute_most_common_normalized_words(train_normalized_words_to_stats_author, most_common_normalized_words_count)\n",
    "    return compute_confusion_matrix_single_author(author_name,all_paragraphs(validation_author), all_paragraphs(validation_other_authors), train_most_common_author , threshold_author_score, verbose)\n",
    "\n",
    "\n",
    "def create_table_with_occurences_corneille_moliere(original_words: List[str]) -> pd.DataFrame:\n",
    "    original_words.sort()\n",
    "    occurences_moliere = []\n",
    "    occurences_corneille = []\n",
    "    for original_word in original_words:\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        occurences_moliere.append(stats_moliere[normalized_word][0] if normalized_word in stats_moliere else 0)\n",
    "        occurences_corneille.append(stats_corneille[normalized_word][0] if normalized_word in stats_corneille else 0)\n",
    "    df =pd.DataFrame(\n",
    "        {'Mot': original_words,\n",
    "        'Molière': occurences_moliere,\n",
    "        'Corneille': occurences_corneille}    )\n",
    "    df.set_index(['Mot'],inplace=True)    \n",
    "    return df   \n",
    "\n",
    "def display_wordcloud(most_common_normalized_words: dict, normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], title:str) -> None:\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "    word_frequencies = dict()\n",
    "    for normalized_word, frequency in most_common_normalized_words.items():\n",
    "        original_word = get_max_item(normalized_words_to_stats[normalized_word][1])[0]\n",
    "        if normalized_word not in stop_words:\n",
    "            word_frequencies[original_word] = frequency\n",
    "    wordcloud = WordCloud(width=1200, height=600, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "    # Display the generated word cloud\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def display_plot(most_common_normalized_words: Dict[str,float], normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], author:str, top_k: int, display_in_percentage: bool):\n",
    "    # Create the bar plot\n",
    "    keys = []\n",
    "    values = []\n",
    "    for normalized_word, frequency in most_common_normalized_words.items():\n",
    "        stats = normalized_words_to_stats[normalized_word]\n",
    "        original_word = get_max_item(stats[1])[0]\n",
    "        if normalized_word not in stop_words:\n",
    "            keys.append(original_word)\n",
    "            if display_in_percentage:\n",
    "                values.append(frequency)\n",
    "            else:\n",
    "                values.append(stats[0])\n",
    "            if len(keys)>=top_k:\n",
    "                break\n",
    "    title = f'Les {top_k} mots les plus communs chez {author}'\n",
    "    display_key_values_plot(keys, values, title, display_in_percentage)\n",
    "\n",
    "def display_dict_plot(dico, title: str, sort_dictionary:bool, display_in_percentage: bool):\n",
    "    if sort_dictionary:\n",
    "        dico = sorted(dico.items(), key = lambda x:x[1], reverse=True)       \n",
    "    keys = [c[0] for c in dico]\n",
    "    frequencies = [c[1] for c in dico]\n",
    "    display_key_values_plot(keys, frequencies, title, display_in_percentage)\n",
    "    \n",
    "def display_key_values_plot(keys: List[str], values, title:str, display_in_percentage: bool):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(range(len(keys)), values, color='blue', tick_label=keys)\n",
    "    # Add title and labels\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.xlabel('Mot', fontsize=15)\n",
    "    if display_in_percentage:\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        plt.ylabel(f\"Fréquence d'occurences\", fontsize=25)\n",
    "    else:\n",
    "        plt.ylabel(f\"Nombre d'occurences\", fontsize=25)\n",
    "    plt.gca().tick_params(axis='y', which='major', labelsize=15) \n",
    "    plt.xticks(rotation=90, fontsize=20)\n",
    "    plt.xlim(-0.5, len(keys) - 0.5)\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3baff9",
   "metadata": {},
   "source": [
    "## PRIVE: Chargement des données et création d'un fichier de statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd281715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moliere_dataset = load_all_books(os.path.join(directory, 'moliere'))\n",
    "stats_moliere = compute_normalized_words_to_stats(all_paragraphs(moliere_dataset))\n",
    "most_common_moliere = compute_most_common_normalized_words(stats_moliere, most_common_normalized_words_count)\n",
    "moliere_total_word_count = sum([c[0] for c in stats_moliere.values()])\n",
    "\n",
    "corneille_dataset = load_all_books(os.path.join(directory, 'corneille'))\n",
    "stats_corneille = compute_normalized_words_to_stats(all_paragraphs(corneille_dataset))\n",
    "most_common_corneille = compute_most_common_normalized_words(stats_corneille, most_common_normalized_words_count)\n",
    "corneille_total_word_count = sum([c[0] for c in stats_corneille.values()])\n",
    "\n",
    "normalized_words = list((set(stats_moliere.keys())|set(stats_corneille.keys())))\n",
    "normalized_words.sort()\n",
    "moliere_normalized_word_count_in_percentage = []\n",
    "moliere_normalized_word_count = []\n",
    "corneille_normalized_word_count_in_percentage = []\n",
    "corneille_normalized_word_count = []\n",
    "moliere_most_common_original_word = []\n",
    "moliere_most_common_original_word_count = []\n",
    "corneille_most_common_original_word = []\n",
    "corneille_most_common_original_word_count = []\n",
    "\n",
    "\n",
    "for normalized_word in normalized_words:\n",
    "    if normalized_word in stats_moliere:\n",
    "        stat = stats_moliere[normalized_word]\n",
    "        moliere_normalized_word_count_in_percentage.append(stat[0]/moliere_total_word_count)\n",
    "        moliere_normalized_word_count.append(stat[0])\n",
    "        most_common_word, most_common_word_count = get_max_item(stat[1])\n",
    "        moliere_most_common_original_word.append(most_common_word)\n",
    "        moliere_most_common_original_word_count.append(most_common_word_count)\n",
    "    else:\n",
    "        moliere_normalized_word_count_in_percentage.append(0)\n",
    "        moliere_normalized_word_count.append(0)\n",
    "        moliere_most_common_original_word.append(None)\n",
    "        moliere_most_common_original_word_count.append(None)\n",
    "    if normalized_word in stats_corneille:\n",
    "        stat = stats_corneille[normalized_word]\n",
    "        corneille_normalized_word_count_in_percentage.append(stat[0]/corneille_total_word_count)\n",
    "        corneille_normalized_word_count.append(stat[0])\n",
    "        most_common_word, most_common_word_count = get_max_item(stat[1])\n",
    "        corneille_most_common_original_word.append(most_common_word)\n",
    "        corneille_most_common_original_word_count.append(most_common_word_count)\n",
    "    else:\n",
    "        corneille_normalized_word_count_in_percentage.append(0)\n",
    "        corneille_normalized_word_count.append(0)\n",
    "        corneille_most_common_original_word.append(None)\n",
    "        corneille_most_common_original_word_count.append(None)\n",
    "\n",
    "fhr_stats = pd.DataFrame(\n",
    "    {'normalized_words': normalized_words,\n",
    "    'moliere_count_in_percentage': moliere_normalized_word_count_in_percentage,\n",
    "    'moliere_count': moliere_normalized_word_count,\n",
    "    'corneille_count_in_percentage' : corneille_normalized_word_count_in_percentage,\n",
    "    'corneille_count' : corneille_normalized_word_count,\n",
    "    'moliere_most_common_original_word' : moliere_most_common_original_word,\n",
    "    'moliere_most_common_original_word_count' : moliere_most_common_original_word_count,\n",
    "    'corneille_most_common_original_word' : corneille_most_common_original_word,\n",
    "    'corneille_most_common_original_word_count' : corneille_most_common_original_word_count,\n",
    "    })\n",
    "\n",
    "# on sauvegarde ces stats sur le disque\n",
    "fhr_stats.to_csv(os.path.join(directory, 'stylometrie_stats.csv'), index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782958cb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">1ère partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159c11e",
   "metadata": {},
   "source": [
    "---\n",
    "# Identification de textes de Molière\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6e47c",
   "metadata": {},
   "source": [
    "## Affichage des mots les plus communs chez Molière"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390b923",
   "metadata": {},
   "source": [
    "### Nuage de mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_wordcloud(most_common_moliere, stats_moliere, \"Molière\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18608b0",
   "metadata": {},
   "source": [
    "### Affichage d'un graphique par nombre d'occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_plot(most_common_moliere, stats_moliere, \"Molière\", 50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb0396",
   "metadata": {},
   "source": [
    "### Affichage d'un graphique  par fréquence d'occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_plot(most_common_moliere, stats_moliere, \"Molière\", 50, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89d78e",
   "metadata": {},
   "source": [
    "### PRIVE: Affichage des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mots les plus fréquents chez Molière\\n\", \"\\n\".join([f'({normalized_word}, {frequency})'for normalized_word,frequency in most_common_moliere.items() if normalized_word not in stop_words ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325a291",
   "metadata": {},
   "source": [
    "## Exemple d'analyse pour un texte de Molière (1ère proposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fef9f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texte_a_analyser = moliere_dataset['les_fourberies_de_scapin'][1]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "\n",
    "normalized_word_to_original_word = compute_normalized_word_to_original_word(texte_a_analyser)\n",
    "most_common_words_found_in_text = dict()\n",
    "for normalized_word,original_word in normalized_word_to_original_word.items():\n",
    "    if normalized_word in most_common_moliere:\n",
    "        normalized_word_frequency = most_common_moliere[normalized_word]\n",
    "        most_common_words_found_in_text[original_word] = normalized_word_frequency\n",
    "\n",
    "title = f\"{len(most_common_words_found_in_text)} mots différents de ce texte (contenant {len(normalized_word_to_original_word)} mots différents)\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Molière\"\n",
    "display_dict_plot(most_common_words_found_in_text, title, True, True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c7177",
   "metadata": {},
   "source": [
    "## Exemple d'analyse pour un texte de Molière (2ème proposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_a_analyser = moliere_dataset['les_fourberies_de_scapin'][1]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "\n",
    "results = []\n",
    "splitted = split_text(texte_a_analyser)\n",
    "for original_word in splitted:\n",
    "    normalized_word = compute_normalized_word(original_word)\n",
    "    if normalized_word in stop_words:\n",
    "        continue\n",
    "    if normalized_word in most_common_moliere:\n",
    "        normalized_word_frequency = most_common_moliere[normalized_word]\n",
    "        results.append( (original_word,normalized_word_frequency) )\n",
    "        \n",
    "results = sorted(results, key=lambda x:x[1], reverse=True)        \n",
    "keys = [ c[0] for c in results]\n",
    "values = [ c[1] for c in results]\n",
    "\n",
    "title = f\"{len(results)} mots de ce texte (contenant {len(splitted)} mots)\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Molière\"\n",
    "display_key_values_plot(keys, values, title, True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cb0d2",
   "metadata": {},
   "source": [
    "## Exemple d'analyse pour un texte de Molière (3ème proposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ff148",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_a_analyser = moliere_dataset['les_fourberies_de_scapin'][1]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "\n",
    "        \n",
    "most_common_words_found_in_text = dict()\n",
    "texte_a_analyser_total_count = 0\n",
    "texte_a_analyser_most_common_count = 0\n",
    "splitted = split_text(texte_a_analyser)\n",
    "for original_word in splitted:\n",
    "    normalized_word = compute_normalized_word(original_word)\n",
    "    if normalized_word in stop_words:\n",
    "        continue\n",
    "    texte_a_analyser_total_count += 1\n",
    "    if normalized_word in most_common_moliere:\n",
    "        normalized_word_frequency = most_common_moliere[normalized_word]\n",
    "        most_common_words_found_in_text[original_word] = normalized_word_frequency\n",
    "        texte_a_analyser_most_common_count += 1\n",
    "\n",
    "title = f\"{texte_a_analyser_most_common_count} mots de ce texte (contenant {len(splitted)} mots)\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Molière\\n(Certains mots peuvent apparaître plusieurs fois)\"\n",
    "display_dict_plot(most_common_words_found_in_text, title, True, True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32acb635",
   "metadata": {},
   "source": [
    "## Affichage d'une courbe permettant de choisir la valeur optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca166aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# commenté car long à tourner\n",
    "valeurs_caracteristique = []\n",
    "precision_caracteristique = []\n",
    "for threshold_author in range(0,50+1,1):\n",
    "    (TP,TN,FP,FN) = train_single_author(moliere_dataset, \"Molière\", corneille_dataset, threshold_author)\n",
    "    accuracy = calcul_accuracy(TP,TN,FP,FN)\n",
    "    valeurs_caracteristique.append(threshold_author)\n",
    "    precision_caracteristique.append(accuracy)\n",
    "    print(f\"threshold_author={threshold_author} => Précision(Molière)={round(accuracy,4)}\")\n",
    "    \n",
    "print(valeurs_caracteristique)\n",
    "print(precision_caracteristique)\n",
    "'''\n",
    "\n",
    "# le code ci dessus (commenté) permet de calculer les valeurs suivantes\n",
    "valeurs_caracteristique = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "precision_caracteristique = [0.5, 0.5, 0.5, 0.5033557046979866, 0.5033557046979866, 0.5067114093959731, 0.5134228187919463, 0.5335570469798657, 0.5570469798657718, 0.6073825503355704, 0.6308724832214765, 0.6610738255033557, 0.7114093959731543, 0.7315436241610739, 0.7214765100671141, 0.7416107382550335, 0.761744966442953, 0.7449664429530202, 0.7114093959731543, 0.6677852348993288, 0.6442953020134228, 0.6241610738255033, 0.5771812080536913, 0.5570469798657718, 0.5469798657718121, 0.5469798657718121, 0.5234899328859061, 0.5100671140939598, 0.5067114093959731, 0.5067114093959731, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, precision_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Précision', color='b')\n",
    "plt.scatter(valeurs_caracteristique, precision_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Nombres minimum de mots signatures de Molière dans un texte pour le considérer comme écrit par Molière', fontsize=20)\n",
    "plt.ylabel('Précision', fontsize=20)\n",
    "plt.title('Evolution de la précision en fonction de la valeur de la caractéristique', fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40b7e1",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ed5f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#la caractéristique à améliorer\n",
    "# ce '10' sera modifé par l'étudiant\n",
    "threshold_author = 10\n",
    "\n",
    "(TP,TN,FP,FN) = train_single_author(moliere_dataset, \"Molière\", corneille_dataset, threshold_author)\n",
    "print(f'Précision(Molière) avec threshold_author={threshold_author}: {round(calcul_accuracy(TP,TN,FP,FN),4)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332715ce",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">2ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563c234",
   "metadata": {},
   "source": [
    "---\n",
    "# Identification de textes de Corneille\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797843f1",
   "metadata": {},
   "source": [
    "## Mots les plus communs chez Corneille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e617484",
   "metadata": {},
   "source": [
    "### Nuage de mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da97c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_wordcloud(most_common_corneille, stats_corneille, \"Corneille\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89c92a",
   "metadata": {},
   "source": [
    "### Affichage d'un graphique par nombre d'occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_plot(most_common_corneille, stats_corneille, \"Corneille\", 50, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa11dc",
   "metadata": {},
   "source": [
    "### Affichage d'un graphique  par fréquence d'occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mots les plus fréquents chez Corneille\\n\", \"\\n\".join([f'({normalized_word}, {frequency})'for normalized_word,frequency in most_common_corneille.items() if normalized_word not in stop_words ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e0657",
   "metadata": {},
   "source": [
    "## Exemple d'analyse pour un texte de Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91288",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_a_analyser = corneille_dataset['le_cid'][1]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "normalized_word_to_original_word = compute_normalized_word_to_original_word(texte_a_analyser)\n",
    "most_common_words_found_in_text = dict()\n",
    "for normalized_word,original_word in normalized_word_to_original_word.items():\n",
    "    if normalized_word in most_common_moliere:\n",
    "        most_common_words_found_in_text[original_word] = most_common_moliere[normalized_word]\n",
    "\n",
    "title = f\"{len(most_common_words_found_in_text)} mots de ce texte (contenant {len(normalized_word_to_original_word)} mots différents)\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Corneille\"\n",
    "display_dict_plot(most_common_words_found_in_text, title, True, True)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9d1c8",
   "metadata": {},
   "source": [
    "## Affichage d'une courbe permettant de choisir la valeur optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79366a05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# commenté car long à tourner\n",
    "'''\n",
    "valeurs_caracteristique = []\n",
    "precision_caracteristique = []\n",
    "for threshold_author in range(0,50+1,1):\n",
    "    (TP,TN,FP,FN) = train_single_author(corneille_dataset, \"Corneille\", moliere_dataset, threshold_author)\n",
    "    accuracy = calcul_accuracy(TP,TN,FP,FN)\n",
    "    valeurs_caracteristique.append(threshold_author)\n",
    "    precision_caracteristique.append(accuracy)\n",
    "    print(f\"threshold_author={threshold_author} => Précision(Corneille)={round(accuracy,4)}\")\n",
    "print(valeurs_caracteristique)\n",
    "print(precision_caracteristique)\n",
    "'''\n",
    "# le code ci dessus (commenté) permet de calculer les valeurs suivantes\n",
    "valeurs_caracteristique = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
    "precision_caracteristique = [0.5, 0.5, 0.5, 0.5033557046979866, 0.5100671140939598, 0.5234899328859061, 0.5503355704697986, 0.6040268456375839, 0.6375838926174496, 0.6644295302013423, 0.7214765100671141, 0.7483221476510067, 0.7651006711409396, 0.7885906040268457, 0.7885906040268457, 0.7718120805369127, 0.7483221476510067, 0.7214765100671141, 0.6812080536912751, 0.6375838926174496, 0.5973154362416108, 0.5805369127516778, 0.5436241610738255, 0.5234899328859061, 0.5167785234899329, 0.5134228187919463, 0.5067114093959731, 0.5067114093959731, 0.5067114093959731, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5033557046979866, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, precision_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Précision', color='b')\n",
    "plt.scatter(valeurs_caracteristique, precision_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Nombres minimum de mots signatures de Molière dans un texte pour le considérer comme écrit par Corneille', fontsize=20)\n",
    "plt.ylabel('Précision', fontsize=20)\n",
    "plt.title('Evolution de la précision en fonction de la valeur de la caractéristique', fontsize=20)\n",
    "plt.legend()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a085a69",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1987e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#la caractéristique à améliorer\n",
    "# ce '10' sera modifé par l'étudiant\n",
    "threshold_author = 10\n",
    "\n",
    "(TP,TN,FP,FN) = train_single_author(corneille_dataset, \"Corneille\", moliere_dataset, threshold_author)\n",
    "print(f'Précision(Corneille) avec threshold_author={threshold_author}: {round(calcul_accuracy(TP,TN,FP,FN),4)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8112d8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">3ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132401f",
   "metadata": {},
   "source": [
    "---\n",
    "# Différencier des textes de Molière et de Corneille\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49cf1d",
   "metadata": {},
   "source": [
    "# PRIVE: outil de recherche de textes très spécifiques à Molière ou Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_score_moliere_vs_corneille(count_moliere:int, total_words_moliere:int, count_corneille:int, total_words_corneille:int ):\n",
    "    if count_moliere+count_corneille<30:\n",
    "        return 0\n",
    "    if count_moliere == 0:\n",
    "        return -1\n",
    "    if count_corneille == 0:\n",
    "        return 1\n",
    "    percentage_moliere = count_moliere/total_words_moliere\n",
    "    percentage_corneille = count_corneille/total_words_corneille\n",
    "    if percentage_moliere>2*percentage_corneille:\n",
    "        return 1\n",
    "    if percentage_corneille>2*percentage_moliere:\n",
    "        return -1\n",
    "    return 0\n",
    "    \n",
    "\n",
    "\n",
    "def find_most_distinctive_lines(is_moliere: bool) -> None:\n",
    "    min_score_moliere = 0\n",
    "    max_score_moliere = 0\n",
    "    \n",
    "    author_dataset = moliere_dataset if is_moliere else corneille_dataset\n",
    "    \n",
    "    for book_name, paragraphs in author_dataset.items():\n",
    "        for paragraph in paragraphs:\n",
    "            for line in paragraph.splitlines():\n",
    "                words = split_text(line)\n",
    "                if len(words)<5:\n",
    "                    continue\n",
    "                line_score_moliere_vs_corneille = 0\n",
    "                comment_moliere = \"\"\n",
    "                comment_corneille = \"\"\n",
    "                for original_word in words:\n",
    "                    normalized_word = compute_normalized_word(original_word)\n",
    "                    count_moliere = stats_moliere[normalized_word][0] if normalized_word in stats_moliere else 0\n",
    "                    count_corneille = stats_corneille[normalized_word][0] if normalized_word in stats_corneille else 0\n",
    "                    word_score_moliere_vs_corneille = compute_word_score_moliere_vs_corneille(count_moliere, moliere_total_word_count, count_corneille, corneille_total_word_count)\n",
    "                    if word_score_moliere_vs_corneille == 0:\n",
    "                        continue\n",
    "                    if is_moliere:\n",
    "                        comment = f\"{original_word} ({count_moliere} vs {count_corneille}) \"\n",
    "                    else:\n",
    "                        comment = f\"{original_word} ({count_corneille} vs {count_moliere}) \"\n",
    "                    if word_score_moliere_vs_corneille>0:\n",
    "                        comment_moliere += comment\n",
    "                    else:\n",
    "                        comment_corneille += comment\n",
    "                    line_score_moliere_vs_corneille += word_score_moliere_vs_corneille\n",
    "                if is_moliere and comment_corneille:\n",
    "                    continue\n",
    "                if not is_moliere and comment_moliere:\n",
    "                    continue\n",
    "                if abs(line_score_moliere_vs_corneille)>=5 and (len(comment_moliere)==0 or len(comment_corneille)==0):\n",
    "                #if total_score_moliere<min_score_moliere or line_score_moliere_vs_corneille>max_score_moliere:\n",
    "                    min_score_moliere = min(min_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    max_score_moliere = max(max_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    print('-'*50)\n",
    "                    print(f\"Oeuvre de {'Molière' if is_moliere else 'Corneille'}: {book_name}\")\n",
    "                    print(line)\n",
    "                    print(f'Score: {line_score_moliere_vs_corneille}')\n",
    "                    if comment_moliere:\n",
    "                        print(f'avantage Molière: {comment_moliere}')\n",
    "                    if comment_corneille:\n",
    "                        print(f'avantage Corneille: {comment_corneille}')\n",
    "                    print('-'*50)\n",
    "                    print()\n",
    "\n",
    "'''\n",
    "Exemples de textes trouvés par cet outil:\n",
    "\n",
    "--------------------------------------------------\n",
    "Oeuvre de Molière: le_malade_imaginaire\n",
    "Qu'il se fasse médecin, je consens au mariage. Oui, faites-vous médecin, je vous donne ma fille.\n",
    "Score: 5\n",
    "avantage Molière: médecin (208 vs 1) mariage (181 vs 24) Oui (849 vs 165) médecin (208 vs 1) fille (415 vs 128) \n",
    "\n",
    "--------------------------------------------------\n",
    "Oeuvre de Corneille: polyeucte\n",
    "Ton courage était bon, ton devoir l'a trahi.\n",
    "Score: -7\n",
    "avantage Corneille: Ton (759 vs 224) courage (206 vs 44) était (86 vs 1) ton (759 vs 224) devoir (182 vs 69) l'a (121 vs 72) trahi (22 vs 8) \n",
    "'''                    \n",
    "                    \n",
    "                \n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Molière')\n",
    "find_most_distinctive_lines(True)\n",
    "print()\n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Corneille')\n",
    "find_most_distinctive_lines(False)\n",
    "print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a5dad",
   "metadata": {},
   "source": [
    "## On montre des exemples où les deux auteurs font une utilisation très différente de certains mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12032ba7",
   "metadata": {},
   "source": [
    "## Nombre d'occurences de certains mots dans l'oeuvre de Molière et Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ecff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots = ['courage', 'devoir', 'fille', 'madame', 'monsieur', 'médecin', 'oui', 'reine', 'trahi', 'trone']\n",
    "for word in mots:\n",
    "    normalized_word = compute_normalized_word(word)\n",
    "    print(f\"Le mot '{word}':\")\n",
    "    print(f'\\test présent {stats_moliere[normalized_word][0]} fois chez Molière:  ', stats_moliere[normalized_word][1])\n",
    "    print(f'\\test présent {stats_corneille[normalized_word][0]} fois chez Corneille:', stats_corneille[normalized_word][1])\n",
    "\n",
    "\n",
    "create_table_with_occurences_corneille_moliere(mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8c327",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Oui, faites-vous médecin, je vous donne ma fille.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e38ca8",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Ton courage était bon, ton devoir l'a trahi.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5078a11",
   "metadata": {},
   "source": [
    "## PRIVE: Entraînement et calcul des métriques avec deux auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c3a62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_confusion_matrix_all_authors(text_moliere: List[str], text_corneille: List[str], most_common_words_moliere: dict , most_common_words_corneille: dict, verbose:bool = False) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = Molière ,  y_pred = Molière\n",
    "    TN = 0 # y_true = Corneille, y_pred = Corneille\n",
    "    FN = 0 # y_true = Molière,   y_pred = Corneille\n",
    "    FP = 0 # y_true = Corneille, y_pred = Molière \n",
    "    for t in text_moliere:\n",
    "        score_moliere = compute_author_score(t, most_common_words_moliere)\n",
    "        score_corneille = compute_author_score(t, most_common_words_corneille)\n",
    "        if score_moliere>score_corneille:\n",
    "            if TP == 0 and verbose:\n",
    "                print(f'\\nExemple de TP (Texte de Molière, bien identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            TP += 1\n",
    "        else:\n",
    "            if FN == 0 and verbose:\n",
    "                print(f'\\nExemple de FN (Texte de Molière, mal identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            FN += 1\n",
    "    for t in text_corneille:\n",
    "        score_moliere = compute_author_score(t, most_common_words_moliere)\n",
    "        score_corneille = compute_author_score(t, most_common_words_corneille)\n",
    "        if score_moliere>score_corneille:\n",
    "            if FP == 0 and verbose:\n",
    "                print(f'\\nExemple de FP (Texte de Corneille, mal identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            FP += 1\n",
    "        else:\n",
    "            if TN == 0 and verbose:\n",
    "                print(f'\\nExemple de TN (Texte de Corneille, bien identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "    \n",
    "def train_all_authors(most_common_count, verbose: bool = False):\n",
    "    random.seed(42)\n",
    "    if verbose: \n",
    "        print(f'\\nMoliere Dataset: {paragraph_count(moliere_dataset)} paragraphes ({word_count(moliere_dataset)} mots) venant de {len(moliere_dataset)} oeuvres:\\n{list(moliere_dataset.keys())}')\n",
    "        print(f'\\nCorneille Dataset: {paragraph_count(corneille_dataset)} paragraphes ({word_count(corneille_dataset)} mots) venant de {len(corneille_dataset)} oeuvres:\\n{list(corneille_dataset.keys())}')\n",
    "\n",
    "    train_moliere,validation_moliere,train_corneille,validation_corneille = split_train_validation_all_authors(moliere_dataset, corneille_dataset, percentage_in_train)\n",
    "\n",
    "    if verbose: \n",
    "        print(f'\\nMoliere Train Dataset: {paragraph_count(train_moliere)} paragraphes ({word_count(train_moliere)} mots) venant de {len(train_moliere)} oeuvres:\\n{list(train_moliere.keys())}')\n",
    "        print(f'\\nMoliere Validation Dataset: {paragraph_count(validation_moliere)} paragraphes ({word_count(validation_moliere)} mots) venant de {len(validation_moliere)} oeuvres:\\n{list(validation_moliere.keys())}')\n",
    "        print(f'\\nCorneille Train Dataset: {paragraph_count(train_corneille)} paragraphes ({word_count(train_corneille)} mots) venant de {len(train_corneille)} oeuvres:\\n{list(train_corneille.keys())}')\n",
    "        print(f'\\nCorneille Validation Dataset: {paragraph_count(validation_corneille)} paragraphes ({word_count(validation_corneille)} mots) venant de {len(validation_corneille)} oeuvres:\\n{list(validation_corneille.keys())}')\n",
    "\n",
    "    train_normalized_words_to_stats_moliere = compute_normalized_words_to_stats(all_paragraphs(train_moliere))\n",
    "    train_normalized_words_to_stats_corneille = compute_normalized_words_to_stats(all_paragraphs(train_corneille))\n",
    "\n",
    "    # we only keep the most common words\n",
    "    train_most_common_moliere = compute_most_common_normalized_words(train_normalized_words_to_stats_moliere, most_common_count)\n",
    "    train_most_common_corneille = compute_most_common_normalized_words(train_normalized_words_to_stats_corneille, most_common_count)\n",
    "    return compute_confusion_matrix_all_authors(all_paragraphs(validation_moliere), all_paragraphs(validation_corneille), train_most_common_moliere , train_most_common_corneille, verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819889b4",
   "metadata": {},
   "source": [
    "# Description d'une 1ère méthode pour différencies des textes écrits par Molière et Corneille:\n",
    "## Pour chaque texte à identifier:\n",
    "### - On compte le nombre de mots 'signatures' de chaque auteur présents dans le texte.\n",
    "    (Un mot signature est l'un des 50 mots les plus courants de cet auteur.)\n",
    "### - On attribue le texte à l'auteur ayant le plus grand nombre de mots signatures dans le texte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e576ae3",
   "metadata": {},
   "source": [
    "## Résultats de cette 1ère méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476674c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(TP,TN,FP,FN) = train_all_authors(most_common_normalized_words_count)\n",
    "print(f'Précision(Molière ou Corneille?)= {round(100*calcul_accuracy(TP,TN,FP,FN),1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc47f13",
   "metadata": {},
   "source": [
    "## Pour améliorer ces résultats, on peut proposer à l'étudiant de modifier le nombre de mots signatures associés à chaque auteur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841b52",
   "metadata": {},
   "source": [
    "### On affiche à l'étudant la valeur de la précision pour différentes valeurs du nombre de mots signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenté car long à tourner\n",
    "'''\n",
    "most_common_counts = [50,100,200]+list(range(500,20000,500))\n",
    "accuracy_for_most_common_counts = []\n",
    "for most_common_count in most_common_counts:\n",
    "    (TP,TN,FP,FN) = train_all_authors(most_common_count)\n",
    "    accuracy = calcul_accuracy(TP,TN,FP,FN)\n",
    "    print(f'Précision(Molière ou Corneille?) if most_common_count={most_common_count} = {round(accuracy,4)}')\n",
    "    accuracy_for_most_common_counts.append(accuracy)\n",
    "print(most_common_counts)\n",
    "print(accuracy_for_most_common_counts)\n",
    "'''                                         \n",
    "# le code ci dessus (commenté) permet de calculer les valeurs suivantes\n",
    "most_common_counts = [50, 100, 200, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500]\n",
    "accuracy_for_most_common_counts = [0.9261744966442953, 0.9328859060402684, 0.9362416107382551, 0.9664429530201343, 0.9697986577181208, 0.9865771812080537, 0.9865771812080537, 0.9899328859060402, 0.9966442953020134, 0.9966442953020134, 0.9899328859060402, 0.9798657718120806, 0.9765100671140939, 0.9798657718120806, 0.9731543624161074, 0.9765100671140939, 0.9765100671140939, 0.9731543624161074, 0.9765100671140939, 0.9798657718120806, 0.9765100671140939, 0.9697986577181208, 0.9563758389261745, 0.9429530201342282, 0.9563758389261745, 0.9496644295302014, 0.9496644295302014, 0.9463087248322147, 0.9362416107382551, 0.9295302013422819, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551, 0.9362416107382551]\n",
    "\n",
    "x_dense = np.linspace(min(most_common_counts), max(most_common_counts), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(most_common_counts, accuracy_for_most_common_counts)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Précision', color='b')\n",
    "plt.scatter(most_common_counts, accuracy_for_most_common_counts, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Nombres de mots signatures chez chaque auteur', fontsize=20)\n",
    "plt.ylabel('Précision pour distinguer des oeuvres de Molière et Corneille', fontsize=20)\n",
    "plt.title('Evolution de la précision en fonction du nombre de mots signatures chez chaque auteur', fontsize=20)\n",
    "plt.legend()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf346fa",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#la caractéristique à améliorer\n",
    "# ce '50' sera modifé par l'étudiant\n",
    "nombre_de_mots_signatures_chez_chaque_auteur = 50\n",
    "\n",
    "(TP,TN,FP,FN) = train_all_authors(nombre_de_mots_signatures_chez_chaque_auteur)\n",
    "print()\n",
    "print('-'*80)\n",
    "print(f'Précision(Molière ou Corneille?)={round(100*calcul_accuracy(TP,TN,FP,FN),1)}%')\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721f0fd",
   "metadata": {},
   "source": [
    "## PRIVE: Précision pour chaque oeuvre utilisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6aa076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-'*80+'\\nPrécision pour chaque oeuvre de Moliere\\n'+'-'*80)\n",
    "accuracy_moliere = dict()\n",
    "for book_path in all_txt_files_in_directory(os.path.join(directory, 'moliere')):\n",
    "    (TP,TN,FP,FN) = compute_confusion_matrix_all_authors(split_book_into_paragraphs(book_path), [], most_common_moliere , most_common_corneille, 0)\n",
    "    #print(f\"Accuracy '{pathlib.Path(book_path).stem}': {round(calcul_accuracy(TP,TN,FP,FN),4)}\")\n",
    "    accuracy_moliere[pathlib.Path(book_path).stem] = calcul_accuracy(TP,TN,FP,FN)\n",
    "for e in sorted(accuracy_moliere.items(), key=lambda x: x[1]):\n",
    "    print(e)\n",
    "\n",
    "print()\n",
    "print('-'*80+'\\nPrécision pour chaque oeuvre de Corneille\\n'+'-'*80)\n",
    "accuracy_corneille = dict()\n",
    "for book_path in all_txt_files_in_directory(os.path.join(directory, 'corneille')):\n",
    "    (TP,TN,FP,FN) = compute_confusion_matrix_all_authors([], split_book_into_paragraphs(book_path), most_common_moliere , most_common_corneille, 0)\n",
    "    accuracy_corneille[pathlib.Path(book_path).stem] = calcul_accuracy(TP,TN,FP,FN)\n",
    "for e in sorted(accuracy_corneille.items(), key=lambda x: x[1]):\n",
    "    print(e)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
