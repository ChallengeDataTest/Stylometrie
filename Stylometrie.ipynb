{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fab4cd",
   "metadata": {},
   "source": [
    "# Le but de ce notebook est d'identifier des caractéristiques permettant de différencier des textes écrits par Molière et Corneille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aecb3f",
   "metadata": {},
   "source": [
    "# PRIVE: Hyperparamétres fixés par MathAData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da83bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de caractéres dans chaque paragraphe dont on veut identifier l'auteur\n",
    "# 1000 caractères correspond à environ une page de texte (environ 180 mots)\n",
    "min_paragraph_length = 1000\n",
    "\n",
    "# on divisie les données d'entraînement en 90% en train et 10% en validation\n",
    "# une oeuvre d'un auteur donné doit être entièrement soit en train soit en validation\n",
    "percentage_in_train = 0.9\n",
    "\n",
    "# on ignore les majuscules / minuscules dans les mots: Monsieur == monsieur\n",
    "use_lowercase = True\n",
    "\n",
    "# on ignore les accents:  être == etre\n",
    "use_diacritics = True\n",
    "\n",
    "# cette option permet de ne tenir compte que de la racine du mot.\n",
    "# elle est désactivée car elle dégrade les performances\n",
    "use_stemming = False\n",
    "\n",
    "# nombre de mots signatures chez chaque auteur\n",
    "# on ne regarde que les 'most_common_normalized_words_count' mots les plus courants chez chaque auteur\n",
    "most_common_normalized_words_count = 50\n",
    "\n",
    "# Mots vides. \n",
    "# Ils sont ignorés par l'outil car très communs à la fois chez Molière et chez Corneille\n",
    "stop_words = set([\"de\",\"et\",\"que\",\"je\",\"a\",\"la\",\"le\",\"ne\",\"ce\",\"il\",\"pour\",\"un\",\"qui\",\"me\",\"est\",\"mais\",\"des\",\"moi\",\"votre\",\"qu'il\",\"lui\",\"du\",\"fait\",\"par\",\"se\",\"au\",\"cette\",\"sur\",\"j'ai\",\"avec\",\"tous\",\"vos\",\"ces\",\"n'est\",\"peu\",\"peut\",\"quelque\",\"dont\",\"quoi\",\"aux\",\"donc\",\"d'une\",\"s'il\",\"notre\",\"sais\",\"donne\",\"vois\",\"m'en\",\"cet\",\"autre\",\"puis\",\"assez\",\"quel\",\"veut\",\"va\",\"ils\",\"doit\",\"ont\",\"vu\", \"en\", \"les\", \"vous\", \"mon\",\"pas\",\"si\",\"plus\", \"tout\", \"nous\", \"ma\", \"sans\", \"ou\", \"c'est\", \"bien\", \"dans\",\"une\", \"son\",\"tu\", \"point\", \"mais\", \"mes\", \"d'un\", \"elle\", \"ses\", \"meme\", \"comme\", \"te\", \"sa\", \"ton\", \"ta\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82185316",
   "metadata": {},
   "source": [
    "# PRIVE: Méthodes utilisés dans le Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09dcc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import List,Set,Tuple,Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter,MaxNLocator     \n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "#!pip install unidecode\n",
    "#!pip install wordcloud\n",
    "#!pip install pillow\n",
    "\n",
    "\n",
    "# le répertoire de travail\n",
    "directory = os.path.abspath('')\n",
    "random.seed(42)\n",
    "\n",
    "# retourne tous les fichiers *.txt présents dans le repertoire 'path'\n",
    "def all_txt_files_in_directory(path: str):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.txt')]\n",
    "\n",
    "# infique si la ligne 'ligne' est une ligne valide ou si elle doit être ignorée (par exemple si elle vide)\n",
    "def is_valid_line(line: str) -> bool:\n",
    "    if line.startswith('Scène ') or line.startswith('Acte '):\n",
    "        return False\n",
    "    if len(line)<10:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def split_book_into_paragraphs(path: str) -> List[str]:\n",
    "    result = []\n",
    "    with open(path, encoding='latin1') as file:\n",
    "        current_paragraph = \"\"\n",
    "        for line in file:\n",
    "            if is_valid_line(line):\n",
    "                if current_paragraph :\n",
    "                    current_paragraph += \"\\n\"\n",
    "                current_paragraph += line.rstrip()\n",
    "                if len(current_paragraph) >= min_paragraph_length:\n",
    "                    result.append(current_paragraph) \n",
    "                    current_paragraph = \"\"\n",
    "    if len(current_paragraph) >= min_paragraph_length or (current_paragraph and len(result) == 0):\n",
    "        result.append(current_paragraph) \n",
    "    return result\n",
    "\n",
    "def load_all_books(path: str) -> Dict[str,List[str]]:\n",
    "    book_to_paragraphs = dict()\n",
    "    for book_path in all_txt_files_in_directory(path):\n",
    "        book_to_paragraphs[pathlib.Path(book_path).stem] = split_book_into_paragraphs(book_path)\n",
    "    return book_to_paragraphs\n",
    "\n",
    "# pour supprimer les accents\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def remove_diacritics(word: str) -> str:\n",
    "    import unidecode  \n",
    "    return unidecode.unidecode(word)\n",
    "\n",
    "# mots en minuscules\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def to_lowercase(word: str) -> str:\n",
    "    return word.lower()\n",
    "\n",
    "# pour le stemming\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def to_stemming(word: str) -> str:\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_normalized_word(word: str) -> str:\n",
    "    if use_lowercase:\n",
    "        word = to_lowercase(word)\n",
    "    if use_diacritics:\n",
    "        word = remove_diacritics(word)\n",
    "    if use_stemming:\n",
    "        word = to_stemming(word)\n",
    "    return word\n",
    "\n",
    "def paragraph_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    if not book_to_paragraphs:\n",
    "        return 0\n",
    "    return sum([len(c) for c in book_to_paragraphs.values()])\n",
    "\n",
    "def split_text(text:str) -> List[str]:\n",
    "    return re.findall(r\"\\b[\\w'^\\d]+\\b\", text.rstrip())\n",
    "            \n",
    "def word_count(book_to_paragraphs: Dict[str, List[str]]) -> int:\n",
    "    result = 0\n",
    "    for paragraph in all_paragraphs(book_to_paragraphs):\n",
    "        result += len(split_text(paragraph.rstrip()))\n",
    "    return result\n",
    "\n",
    "def all_paragraphs(book_to_paragraphs: Dict[str, List[str]]) -> List[str]:\n",
    "    result = []\n",
    "    for p in book_to_paragraphs.values():\n",
    "        result.extend(p)\n",
    "    return result\n",
    "\n",
    "# reduce the dataset so that it contains exactly 'target_count' paragraphs\n",
    "def reduce_to_paragraph_count(book_to_paragraphs: dict, target_count: int ) -> int:\n",
    "    current_count = paragraph_count(book_to_paragraphs)\n",
    "    if current_count<target_count:\n",
    "        raise Exception(f'current_count {current_count} < target_count {target_count}')\n",
    "    to_remove = current_count-  target_count\n",
    "    result = dict()\n",
    "    for book, paragraphs in sorted(book_to_paragraphs.items(), key =lambda x : len(x[1])):\n",
    "        if len(paragraphs)<=to_remove:\n",
    "            to_remove-=len(paragraphs)\n",
    "            continue\n",
    "        result[book] = paragraphs[:len(paragraphs)-to_remove]\n",
    "        to_remove = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_most_common_normalized_words(normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], most_common_count:int) -> Dict[str,float]:\n",
    "    sorted_by_total_count = sorted(normalized_words_to_stats.items(), key=lambda item:item[1][0], reverse=True)\n",
    "    total_count = sum([stats[0] for normalized_word,stats in normalized_words_to_stats.items() if normalized_word not in stop_words])\n",
    "    result  = dict()\n",
    "    for normalized_word,stats in sorted_by_total_count:\n",
    "        if normalized_word not in stop_words:\n",
    "            result[normalized_word] = stats[0]/total_count\n",
    "        if len(result)>=most_common_count:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def compute_normalized_words_to_stats(paragraphs: List[str]) -> Dict[str, Tuple[int,Dict[str,int]] ]:\n",
    "    normalized_words_to_stats = dict()\n",
    "    for paragraph in paragraphs:\n",
    "        words = split_text(paragraph)\n",
    "        for original_word in words:\n",
    "            normalized_word = compute_normalized_word(original_word)\n",
    "            if normalized_word not in normalized_words_to_stats:\n",
    "                normalized_words_to_stats[normalized_word] = (0, dict())\n",
    "            count,original_word_count = normalized_words_to_stats[normalized_word]\n",
    "            if original_word not in original_word_count:\n",
    "                original_word_count[original_word] = 1\n",
    "            else:\n",
    "                original_word_count[original_word] += 1\n",
    "            normalized_words_to_stats[normalized_word] = (count+1,original_word_count)\n",
    "    return normalized_words_to_stats\n",
    "\n",
    "def compute_normalized_word_to_original_word(text: str) -> Dict[str,str]:\n",
    "    normalized_word_to_original_word = dict()\n",
    "    splitted_text = split_text(text)\n",
    "    for original_word in splitted_text:\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in stop_words:\n",
    "            continue\n",
    "        normalized_word_to_original_word[normalized_word] = original_word\n",
    "    return normalized_word_to_original_word\n",
    "\n",
    "def get_max_item(dic: Dict[str, int]) -> Tuple[str,int]:\n",
    "    key_max_count, max_count = (None, None)\n",
    "    for key,count in dic.items():\n",
    "        if max_count is None or count > max_count:\n",
    "            key_max_count, max_count = key, count\n",
    "    return key_max_count, max_count\n",
    "    \n",
    "def split_train_validation_single_author(book_to_paragraphs: dict, percentage_in_train:float) :\n",
    "    books = list(book_to_paragraphs.keys())\n",
    "    train = dict()\n",
    "    validation = dict()\n",
    "    for book, paragraphs in book_to_paragraphs.items():\n",
    "        paragraphs_count = len(paragraphs)\n",
    "        percentage_in_train_if_adding_to_train = (paragraph_count(train)+len(paragraphs))/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        percentage_in_train_if_adding_to_validation = paragraph_count(train)/max(paragraph_count(train)+paragraph_count(validation)+len(paragraphs),1)\n",
    "        if abs(percentage_in_train_if_adding_to_train-percentage_in_train)<abs(percentage_in_train_if_adding_to_validation-percentage_in_train):\n",
    "            train[book] = paragraphs\n",
    "        else:\n",
    "            validation[book] = paragraphs\n",
    "    return train, validation\n",
    "\n",
    "def split_train_validation_all_authors(book_to_paragraphs_author1: dict, book_to_paragraphs_author2: dict, percentage_in_train:float) :\n",
    "    train_author1,validation_author1 = split_train_validation_single_author(book_to_paragraphs_author1, percentage_in_train)\n",
    "    train_author2,validation_author2 = split_train_validation_single_author(book_to_paragraphs_author2, percentage_in_train)\n",
    "\n",
    "    target_length_validation = min(paragraph_count(validation_author1),paragraph_count(validation_author2))            \n",
    "    validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "    validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "\n",
    "    target_length_train = min(paragraph_count(train_author1),paragraph_count(train_author2))            \n",
    "    train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "    train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "\n",
    "    proportion_in_train = target_length_train/(target_length_train+target_length_validation)\n",
    "    if proportion_in_train>percentage_in_train:\n",
    "        target_length_train = int( (percentage_in_train/(1-percentage_in_train)) *target_length_validation )\n",
    "        train_author1 = reduce_to_paragraph_count(train_author1, target_length_train)\n",
    "        train_author2 = reduce_to_paragraph_count(train_author2, target_length_train)\n",
    "    else:\n",
    "        target_length_validation = int( ((1-percentage_in_train)/percentage_in_train) *target_length_train )\n",
    "        validation_author1 = reduce_to_paragraph_count(validation_author1, target_length_validation)\n",
    "        validation_author2 = reduce_to_paragraph_count(validation_author2, target_length_validation)\n",
    "    return train_author1,validation_author1,train_author2,validation_author2\n",
    "\n",
    "def compute_error(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1-(TP+TN)/max(TP+TN+FP+FN,1)\n",
    "\n",
    "def calcul_1ere_caracteristique(text:str, most_common_words_for_author: Dict[str,float]) -> float:\n",
    "    # nombre de mots signatures de l'auteur présents dans le texte 'text'\n",
    "    valeur_1ere_caracteristique = 0\n",
    "    for original_word in split_text(text):\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in most_common_words_for_author:\n",
    "            valeur_1ere_caracteristique += 1\n",
    "    return valeur_1ere_caracteristique\n",
    "\n",
    "def compute_confusion_matrix_single_author(author_name:str, texts_from_author: List[str], text_from_other_authors: List[str], most_common_words_from_author: dict , seuil_1ere_caracteristique: int, verbose:bool) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = author_name ,  y_pred = author_name\n",
    "    TN = 0 # y_true = another author, y_pred = another author\n",
    "    FN = 0 # y_true = author_name,   y_pred = another author\n",
    "    FP = 0 # y_true = another_author, y_pred = author_name \n",
    "    for t in texts_from_author:\n",
    "        valeur_1ere_caracteristique = calcul_1ere_caracteristique(t, most_common_words_from_author)\n",
    "        if valeur_1ere_caracteristique>=seuil_1ere_caracteristique:\n",
    "            if TP == 0 and verbose:\n",
    "                print(f'\\nExemple de TP (Texte de {author_name}, bien identifié, score {author_name}: {round(valeur_1ere_caracteristique,4)}):\\n{t}\\n')\n",
    "            TP += 1\n",
    "        else:\n",
    "            if FN == 0 and verbose:\n",
    "                print(f'\\nExemple de FN (Texte de {author_name}, mal identifié, score {author_name}: {round(valeur_1ere_caracteristique,4)}):\\n{t}\\n')\n",
    "            FN += 1\n",
    "    for t in text_from_other_authors:\n",
    "        valeur_1ere_caracteristique = calcul_1ere_caracteristique(t, most_common_words_from_author)\n",
    "        if valeur_1ere_caracteristique>=seuil_1ere_caracteristique:\n",
    "            if FP == 0 and verbose:\n",
    "                print(f\"\\nExemple de FP (Texte d'un autre auteur, mal identifié, score {valeur_1ere_caracteristique}: {round(valeur_1ere_caracteristique,4)}):\\n{t}\\n\")\n",
    "            FP += 1\n",
    "        else:\n",
    "            if TN == 0 and verbose:\n",
    "                print(f\"\\nExemple de TN (Texte d'un autre auteur, bien identifié, score {valeur_1ere_caracteristique}: {round(valeur_1ere_caracteristique,4)}):\\n{t}\\n\")\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "def train_single_author(author_dataset, author_name, other_authors_dataset, seuil_1ere_caracteristique: int, verbose: bool = False) -> Tuple[float, float]:\n",
    "    random.seed(42)\n",
    "    if verbose: \n",
    "        print(f'\\n{author_name} Dataset: {paragraph_count(author_dataset)} paragraphes ({word_count(author_dataset)} mots) venant de {len(author_dataset)} oeuvres:\\n{list(author_dataset.keys())}')\n",
    "        print(f'\\nother_authors Dataset: {paragraph_count(other_authors_dataset)} paragraphes ({word_count(other_authors_dataset)} mots) venant de {len(other_authors_dataset)} oeuvres:\\n{list(other_authors_dataset.keys())}')\n",
    "\n",
    "    train_author,validation_author,train_other_authors,validation_other_authors = split_train_validation_all_authors(author_dataset, other_authors_dataset, percentage_in_train)\n",
    "\n",
    "    if verbose: \n",
    "        print(f'\\n{author_name} Train Dataset: {paragraph_count(train_author)} paragraphes ({word_count(train_author)} mots) venant de {len(train_author)} oeuvres:\\n{list(train_author.keys())}')\n",
    "        print(f'\\n{author_name} Validation Dataset: {paragraph_count(validation_author)} paragraphes ({word_count(validation_author)} mots) venant de {len(validation_author)} oeuvres:\\n{list(validation_author.keys())}')\n",
    "        print(f'\\nother_authors Train Dataset: {paragraph_count(train_other_authors)} paragraphes ({word_count(train_other_authors)} mots) venant de {len(train_other_authors)} oeuvres:\\n{list(train_other_authors.keys())}')\n",
    "        print(f'\\nother_authors Validation Dataset: {paragraph_count(validation_other_authors)} paragraphes ({word_count(validation_other_authors)} mots) venant de {len(validation_other_authors)} oeuvres:\\n{list(validation_other_authors.keys())}')\n",
    "\n",
    "    train_normalized_words_to_stats_author = compute_normalized_words_to_stats(all_paragraphs(train_author))\n",
    "    # we only keep the most common words\n",
    "    train_most_common_author = compute_most_common_normalized_words(train_normalized_words_to_stats_author, most_common_normalized_words_count)\n",
    "    train_error = compute_error(*compute_confusion_matrix_single_author(author_name,all_paragraphs(train_author), all_paragraphs(train_other_authors), train_most_common_author , seuil_1ere_caracteristique, verbose))\n",
    "    validation_error = compute_error(*compute_confusion_matrix_single_author(author_name,all_paragraphs(validation_author), all_paragraphs(validation_other_authors), train_most_common_author , seuil_1ere_caracteristique, verbose))\n",
    "    return train_error,validation_error\n",
    "\n",
    "def create_table_with_occurences_corneille_moliere(original_words: List[str]) -> pd.DataFrame:\n",
    "\n",
    "    original_words.sort()\n",
    "    occurences_moliere = []\n",
    "    occurences_corneille = []\n",
    "    frequence_moliere = []\n",
    "    frequence_corneille = []\n",
    "    for original_word in original_words:\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        occurences_moliere.append(stats_moliere[normalized_word][0] if normalized_word in stats_moliere else 0)\n",
    "        occurences_corneille.append(stats_corneille[normalized_word][0] if normalized_word in stats_corneille else 0)\n",
    "        frequence_moliere.append(stats_moliere[normalized_word][0]/moliere_total_word_count_without_stopwords if normalized_word in stats_moliere else 0)\n",
    "        frequence_corneille.append(stats_corneille[normalized_word][0]/corneille_total_word_count_without_stopwords if normalized_word in stats_corneille else 0)\n",
    "    df =pd.DataFrame(\n",
    "        {'Mot': original_words,\n",
    "        'Occurences Molière': occurences_moliere,\n",
    "        'Occurences Corneille': occurences_corneille,\n",
    "        'Fréquence Molière': frequence_moliere,\n",
    "        'Fréquence Corneille': frequence_corneille} \n",
    "        )\n",
    "    df.set_index(['Mot'],inplace=True)    \n",
    "    return df   \n",
    "\n",
    "def display_wordcloud(most_common_normalized_words: dict, normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], title:str) -> None:\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "    word_frequencies = dict()\n",
    "    for normalized_word, frequency in most_common_normalized_words.items():\n",
    "        original_word = get_max_item(normalized_words_to_stats[normalized_word][1])[0]\n",
    "        if normalized_word not in stop_words:\n",
    "            word_frequencies[original_word] = frequency\n",
    "    wordcloud = WordCloud(width=1200, height=600, background_color='white').generate_from_frequencies(word_frequencies)\n",
    "    # Display the generated word cloud\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def display_plot(most_common_normalized_words: Dict[str,float], normalized_words_to_stats: Dict[str, Tuple[int,Dict[str,int]] ], author:str, top_k: int, display_in_percentage: bool):\n",
    "    # Create the bar plot\n",
    "    keys = []\n",
    "    values = []\n",
    "    for normalized_word, frequency in most_common_normalized_words.items():\n",
    "        stats = normalized_words_to_stats[normalized_word]\n",
    "        original_word = get_max_item(stats[1])[0]\n",
    "        if normalized_word not in stop_words:\n",
    "            keys.append(original_word)\n",
    "            if display_in_percentage:\n",
    "                values.append(frequency)\n",
    "            else:\n",
    "                values.append(stats[0])\n",
    "            if len(keys)>=top_k:\n",
    "                break\n",
    "    title = f'Les {top_k} mots les plus communs chez {author}'\n",
    "    display_key_values_plot(keys, values, title, display_in_percentage)\n",
    "\n",
    "def display_dict_plot(dico, title: str, sort_dictionary:bool, display_in_percentage: bool):\n",
    "    if sort_dictionary:\n",
    "        dico = sorted(dico.items(), key = lambda x:x[1], reverse=True)       \n",
    "    keys = [c[0] for c in dico]\n",
    "    frequencies = [c[1] for c in dico]\n",
    "    display_key_values_plot(keys, frequencies, title, display_in_percentage)\n",
    "    \n",
    "def display_key_values_plot(keys: List[str], values, title:str, display_in_percentage: bool):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(range(len(keys)), values, color='blue', tick_label=keys)\n",
    "    # Add title and labels\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.xlabel('Mot', fontsize=15)\n",
    "    if display_in_percentage:\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        plt.ylabel(f\"Fréquence d'occurences\", fontsize=25)\n",
    "    else:\n",
    "        plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel(f\"Nombre d'occurences\", fontsize=25)\n",
    "    plt.gca().tick_params(axis='y', which='major', labelsize=15) \n",
    "    plt.xticks(rotation=90, fontsize=20)\n",
    "    plt.xlim(-0.5, len(keys) - 0.5)\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3baff9",
   "metadata": {},
   "source": [
    "## PRIVE: Chargement des données et création d'un fichier de statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd281715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moliere_dataset = load_all_books(os.path.join(directory, 'moliere'))\n",
    "stats_moliere = compute_normalized_words_to_stats(all_paragraphs(moliere_dataset))\n",
    "most_common_moliere = compute_most_common_normalized_words(stats_moliere, most_common_normalized_words_count)\n",
    "moliere_total_word_count = sum([c[0] for c in stats_moliere.values()])\n",
    "moliere_total_word_count_without_stopwords = sum([stats[0] for normalized_word,stats in stats_moliere.items() if normalized_word not in stop_words])\n",
    "\n",
    "\n",
    "\n",
    "corneille_dataset = load_all_books(os.path.join(directory, 'corneille'))\n",
    "stats_corneille = compute_normalized_words_to_stats(all_paragraphs(corneille_dataset))\n",
    "most_common_corneille = compute_most_common_normalized_words(stats_corneille, most_common_normalized_words_count)\n",
    "corneille_total_word_count = sum([c[0] for c in stats_corneille.values()])\n",
    "corneille_total_word_count_without_stopwords = sum([stats[0] for normalized_word,stats in stats_corneille.items() if normalized_word not in stop_words])\n",
    "\n",
    "normalized_words = list((set(stats_moliere.keys())|set(stats_corneille.keys())))\n",
    "normalized_words.sort()\n",
    "moliere_normalized_word_count_in_percentage = []\n",
    "moliere_normalized_word_count = []\n",
    "corneille_normalized_word_count_in_percentage = []\n",
    "corneille_normalized_word_count = []\n",
    "moliere_most_common_original_word = []\n",
    "moliere_most_common_original_word_count = []\n",
    "corneille_most_common_original_word = []\n",
    "corneille_most_common_original_word_count = []\n",
    "\n",
    "\n",
    "for normalized_word in normalized_words:\n",
    "    if normalized_word in stats_moliere:\n",
    "        stat = stats_moliere[normalized_word]\n",
    "        moliere_normalized_word_count_in_percentage.append(stat[0]/moliere_total_word_count)\n",
    "        moliere_normalized_word_count.append(stat[0])\n",
    "        most_common_word, most_common_word_count = get_max_item(stat[1])\n",
    "        moliere_most_common_original_word.append(most_common_word)\n",
    "        moliere_most_common_original_word_count.append(most_common_word_count)\n",
    "    else:\n",
    "        moliere_normalized_word_count_in_percentage.append(0)\n",
    "        moliere_normalized_word_count.append(0)\n",
    "        moliere_most_common_original_word.append(None)\n",
    "        moliere_most_common_original_word_count.append(None)\n",
    "    if normalized_word in stats_corneille:\n",
    "        stat = stats_corneille[normalized_word]\n",
    "        corneille_normalized_word_count_in_percentage.append(stat[0]/corneille_total_word_count)\n",
    "        corneille_normalized_word_count.append(stat[0])\n",
    "        most_common_word, most_common_word_count = get_max_item(stat[1])\n",
    "        corneille_most_common_original_word.append(most_common_word)\n",
    "        corneille_most_common_original_word_count.append(most_common_word_count)\n",
    "    else:\n",
    "        corneille_normalized_word_count_in_percentage.append(0)\n",
    "        corneille_normalized_word_count.append(0)\n",
    "        corneille_most_common_original_word.append(None)\n",
    "        corneille_most_common_original_word_count.append(None)\n",
    "\n",
    "fhr_stats = pd.DataFrame(\n",
    "    {'normalized_words': normalized_words,\n",
    "    'moliere_count_in_percentage': moliere_normalized_word_count_in_percentage,\n",
    "    'moliere_count': moliere_normalized_word_count,\n",
    "    'corneille_count_in_percentage' : corneille_normalized_word_count_in_percentage,\n",
    "    'corneille_count' : corneille_normalized_word_count,\n",
    "    'moliere_most_common_original_word' : moliere_most_common_original_word,\n",
    "    'moliere_most_common_original_word_count' : moliere_most_common_original_word_count,\n",
    "    'corneille_most_common_original_word' : corneille_most_common_original_word,\n",
    "    'corneille_most_common_original_word_count' : corneille_most_common_original_word_count,\n",
    "    })\n",
    "\n",
    "# on sauvegarde ces stats sur le disque\n",
    "fhr_stats.to_csv(os.path.join(directory, 'stylometrie_stats.csv'), index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32acb635",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 60px;\"><b>1ère caractéristique</b></span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 28px;\">Nombre de 'mots signatures' d'un auteur présent dans un texte donné.</span><br>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\"><br>\n",
    "<span style=\"font-size: 24px;\"><i>Un 'mot signature' d'un auteur est un mot très fréquemment utilisé dans son œuvre.</i></span>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782958cb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">1ère partie: </span><span style=\"font-size: 36px;\">(basée sur la 1ère caractéristique)</span><br><br>\n",
    "<span style=\"font-size: 36px;\">Déterminer si un texte a été écrit par Molière.</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 24px;\"><u>Méthode utilisée:</u></span><br>\n",
    "<span style=\"font-size: 24px;\">1. On calcule les 50 mots les plus courants chez Molière (ses 'mots signatures').</span><br>\n",
    "<span style=\"font-size: 24px;\">2. On calcule le nombre de mots signatures de Molière présent dans ce texte.</span><br>\n",
    "<span style=\"font-size: 24px;\">3. Si ce nombre dépasse un certain seuil, on attribue ce texte à Molière.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6e47c",
   "metadata": {},
   "source": [
    "## Affichage des 50 mots les plus fréquemment utilisés  chez Molière"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390b923",
   "metadata": {},
   "source": [
    "### Nuage de mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_wordcloud(most_common_moliere, stats_moliere, \"Molière\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b890769",
   "metadata": {},
   "source": [
    "### Graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_plot(most_common_moliere, stats_moliere, \"Molière\", 50, True)\n",
    "\n",
    "# Affichage d'un graphique par nombre d'occurences\n",
    "#display_plot(most_common_moliere, stats_moliere, \"Molière\", 50, False)\n",
    "\n",
    "# Affichage des données brutes\n",
    "#print(\"Mots les plus fréquents chez Molière\\n\", \"\\n\".join([f'({normalized_word}, {frequency})'for normalized_word,frequency in most_common_moliere.items() if normalized_word not in stop_words ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cb0d2",
   "metadata": {},
   "source": [
    "## Exemple de calcul de cette 1ère caractéristique pour un texte de Molière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ff148",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_a_analyser = moliere_dataset['les_fourberies_de_scapin'][1]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "        \n",
    "most_common_words_found_in_text = defaultdict(int)\n",
    "for original_word in split_text(texte_a_analyser):\n",
    "    normalized_word = compute_normalized_word(original_word)\n",
    "    if normalized_word in most_common_moliere:\n",
    "        most_common_words_found_in_text[normalized_word] += 1\n",
    "\n",
    "title = f\"{len(most_common_words_found_in_text)} mots différents de ce texte, apparaissant au total {sum(most_common_words_found_in_text.values())} fois,\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Molière\\n Valeur de la 1ère carcactéristiqe pour ce texte: {sum(most_common_words_found_in_text.values())}\"\n",
    "display_key_values_plot(list(most_common_words_found_in_text.keys()), list(most_common_words_found_in_text.values()), title, display_in_percentage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b5039",
   "metadata": {},
   "source": [
    "## Affichage d'une courbe permettant de choisir la valeur optimale du seuil associé à la valeur de la 1ère caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca166aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeur_seuils = []\n",
    "erreur_seuils = []\n",
    "for seuil_1ere_caracteristique_moliere in range(0,40+1,2):\n",
    "    (train_error, validation_error) = train_single_author(moliere_dataset, \"Molière\", corneille_dataset, seuil_1ere_caracteristique_moliere)\n",
    "    valeur_seuils.append(seuil_1ere_caracteristique_moliere)\n",
    "    erreur_seuils.append(train_error)\n",
    "    print(f\"seuil 1ère caractéristique={seuil_1ere_caracteristique_moliere} => Erreur(Molière)={round(100*train_error,1)}%\")\n",
    "\n",
    "# le code ci dessous (commenté) permet d'éviter de recalculer les valeurs\n",
    "#print(valeur_seuils)\n",
    "#print(erreur_seuils)\n",
    "#valeur_seuils = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40]\n",
    "#erreur_seuils = [0.5, 0.5, 0.4955555555555555, 0.4722222222222222, 0.42259259259259263, 0.35111111111111115, 0.2818518518518518, 0.2625925925925926, 0.26962962962962966, 0.3177777777777778, 0.3622222222222222, 0.39888888888888885, 0.43074074074074076, 0.4522222222222222, 0.4707407407407408, 0.4792592592592593, 0.4833333333333333, 0.48703703703703705, 0.48962962962962964, 0.49370370370370376, 0.49629629629629635]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min(valeur_seuils), max(valeur_seuils), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeur_seuils, erreur_seuils)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeur_seuils, erreur_seuils, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlim(0, max(valeur_seuils))\n",
    "plt.xlabel('Seuil associé à la 1ère caractéristique.\\n(nombres minimum de mots signatures de Molière dans un texte pour le considérer comme écrit par Molière)', fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.title(\"Evolution de l'erreur en fonction de la valeur du seuil associé à la 1ère caractéristique\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40b7e1",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir le seuil associé à cette 1ère caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ed5f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seuil associé à cette 1ère caractéristique\n",
    "# Si le nombre de mots signatures de Molière dans un texte est >= à ce seuil, alors ce texte sera attribué à Molière\n",
    "# ce '10' sera modifé par l'étudiant\n",
    "seuil_1ere_caracteristique = 10\n",
    "(train_error, validation_error) = train_single_author(moliere_dataset, \"Molière\", corneille_dataset, seuil_1ere_caracteristique)\n",
    "print(f\"Erreur(Molière) avec 'seuil 1ère cacactéristique' = {seuil_1ere_caracteristique}  :  {round(100*validation_error,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332715ce",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">2ème partie: </span><span style=\"font-size: 36px;\">(basée sur la 1ère caractéristique)</span><br><br>\n",
    "<span style=\"font-size: 36px;\">Déterminer si un texte a été écrit par Corneille.</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 24px;\"><u>Méthode utilisée:</u></span><br>\n",
    "<span style=\"font-size: 24px;\">1. On calcule les 50 mots les plus courants chez Corneille (ses 'mots signatures').</span><br>\n",
    "<span style=\"font-size: 24px;\">2. On calcule le nombre de mots signatures de Corneille présent dans ce texte.</span><br>\n",
    "<span style=\"font-size: 24px;\">3. Si ce nombre dépasse un certain seuil, on attribue ce texte à Corneille.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797843f1",
   "metadata": {},
   "source": [
    "## Affichage des 50 mots les plus fréquemment utilisés  chez Corneille"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e617484",
   "metadata": {},
   "source": [
    "### Nuage de mots-clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da97c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_wordcloud(most_common_corneille, stats_corneille, \"Corneille\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89c92a",
   "metadata": {},
   "source": [
    "### Graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_plot(most_common_corneille, stats_corneille, \"Corneille\", 50, True)\n",
    "\n",
    "# Affichage d'un graphique par nombre d'occurence\n",
    "#display_plot(most_common_corneille, stats_corneille, \"Corneille\", 50, False)\n",
    "\n",
    "# Affichage des données brutes\n",
    "#print(\"Mots les plus fréquents chez Corneille\\n\", \"\\n\".join([f'({normalized_word}, {frequency})'for normalized_word,frequency in most_common_corneille.items() if normalized_word not in stop_words ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e0657",
   "metadata": {},
   "source": [
    "## Exemple de calcul de cette 1ère caractéristique pour un texte de Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91288",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_a_analyser = corneille_dataset['le_cid'][2]\n",
    "print('Texte à analyser')\n",
    "print('')\n",
    "print('-'*50)\n",
    "print(texte_a_analyser)\n",
    "print('-'*50)\n",
    "\n",
    "most_common_words_found_in_text = defaultdict(int)\n",
    "for original_word in split_text(texte_a_analyser):\n",
    "    normalized_word = compute_normalized_word(original_word)\n",
    "    if normalized_word in most_common_corneille:\n",
    "        most_common_words_found_in_text[normalized_word] += 1\n",
    "\n",
    "title = f\"{len(most_common_words_found_in_text)} mots différents de ce texte, apparaissant au total {sum(most_common_words_found_in_text.values())} fois,\\nfont partie des {most_common_normalized_words_count} mots les plus courants chez Corneille\\n Valeur de la 1ère carcactéristiqe pour ce texte: {sum(most_common_words_found_in_text.values())}\"\n",
    "display_key_values_plot(list(most_common_words_found_in_text.keys()), list(most_common_words_found_in_text.values()), title, display_in_percentage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9d1c8",
   "metadata": {},
   "source": [
    "## Affichage d'une courbe permettant de choisir la valeur optimale du seuil associé à la valeur de la 1ère caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79366a05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valeur_seuils = []\n",
    "erreur_seuils = []\n",
    "for seuil_1ere_caracteristique_corneille in range(0,40+1,2):\n",
    "    (train_error, validation_error) = train_single_author(corneille_dataset, \"Corneille\", moliere_dataset, seuil_1ere_caracteristique_corneille)\n",
    "    valeur_seuils.append(seuil_1ere_caracteristique_corneille)\n",
    "    erreur_seuils.append(validation_error)\n",
    "    print(f\"seuil 1ère caractéristique={seuil_1ere_caracteristique_corneille} => Erreur(Corneille)={round(100*validation_error,1)}%\")\n",
    "\n",
    "# le code ci dessous (commenté) permet d'éviter de recalculer les valeurs\n",
    "#print(valeur_seuils)\n",
    "#print(erreur_seuils)\n",
    "#valeur_seuils = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40]\n",
    "#erreur_seuils = [0.5, 0.49888888888888894, 0.4907407407407407, 0.4703703703703703, 0.4396296296296296, 0.39481481481481484, 0.3648148148148148, 0.35777777777777775, 0.36629629629629634, 0.40296296296296297, 0.43518518518518523, 0.4588888888888889, 0.4748148148148148, 0.4848148148148148, 0.49111111111111116, 0.4955555555555555, 0.49851851851851847, 0.4992592592592593, 0.5, 0.5, 0.5]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min(valeur_seuils), max(valeur_seuils), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeur_seuils, erreur_seuils)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeur_seuils, erreur_seuils, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlim(0, max(valeur_seuils))\n",
    "plt.xlabel('Seuil associé à la 1ère caractéristique.\\n(nombres minimum de mots signatures de Corneille dans un texte pour le considérer comme écrit par Corneille)', fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.title(\"Evolution de l'erreur en fonction de la valeur du seuil associé à la 1ère caractéristique\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a085a69",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir le seuil associé à cette 1ère caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1987e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seuil associé à cette 1ère caractéristique\n",
    "# Si le nombre de mots signatures de Molière dans un texte est >= à ce seuil, alors ce texte sera attribué à Molière\n",
    "# ce '10' sera modifé par l'étudiant\n",
    "seuil_1ere_caracteristique = 10\n",
    "(train_error, validation_error) = train_single_author(corneille_dataset, \"Corneille\", moliere_dataset, seuil_1ere_caracteristique)\n",
    "print(f\"Erreur(Corneille) avec 'seuil 1ère cacactéristique' = {seuil_1ere_caracteristique}  :  {round(100*validation_error,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8112d8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">3ème partie: </span><span style=\"font-size: 36px;\">(basée sur la 1ère caractéristique)</span><br><br>\n",
    "<span style=\"font-size: 36px;\">Déterminer si un texte a été écrit par Molière ou par Corneille.</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 24px;\"><u>Méthode utilisée:</u></span><br>\n",
    "<span style=\"font-size: 24px;\">1. On calcule les 50 mots les plus courants chez Molière (ses 'mots signatures').</span><br>\n",
    "<span style=\"font-size: 24px;\">2. On calcule les 50 mots les plus courants chez Corneille (ses 'mots signatures').</span><br>\n",
    "<span style=\"font-size: 24px;\">3. On calcule le nombre de mots signatures de Molière présent dans ce texte.</span><br>\n",
    "<span style=\"font-size: 24px;\">4. On calcule le nombre de mots signatures de Corneille présent dans ce texte.</span><br>\n",
    "<span style=\"font-size: 24px;\">5. On attribue le texte à l'auteur ayant le plus de mots signatures dans ce texte.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5078a11",
   "metadata": {},
   "source": [
    "## PRIVE: Entraînement et calcul des métriques avec deux auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c3a62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_confusion_matrix_all_authors(text_moliere: List[str], text_corneille: List[str], most_common_words_moliere: dict , most_common_words_corneille: dict, verbose:bool = False) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = Molière ,  y_pred = Molière\n",
    "    TN = 0 # y_true = Corneille, y_pred = Corneille\n",
    "    FN = 0 # y_true = Molière,   y_pred = Corneille\n",
    "    FP = 0 # y_true = Corneille, y_pred = Molière \n",
    "    for t in text_moliere:\n",
    "        score_moliere = calcul_1ere_caracteristique(t, most_common_words_moliere)\n",
    "        score_corneille = calcul_1ere_caracteristique(t, most_common_words_corneille)\n",
    "        if score_moliere>score_corneille:\n",
    "            if TP == 0 and verbose:\n",
    "                print(f'\\nExemple de TP (Texte de Molière, bien identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            TP += 1\n",
    "        else:\n",
    "            if FN == 0 and verbose:\n",
    "                print(f'\\nExemple de FN (Texte de Molière, mal identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            FN += 1\n",
    "    for t in text_corneille:\n",
    "        score_moliere = calcul_1ere_caracteristique(t, most_common_words_moliere)\n",
    "        score_corneille = calcul_1ere_caracteristique(t, most_common_words_corneille)\n",
    "        if score_moliere>score_corneille:\n",
    "            if FP == 0 and verbose:\n",
    "                print(f'\\nExemple de FP (Texte de Corneille, mal identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            FP += 1\n",
    "        else:\n",
    "            if TN == 0 and verbose:\n",
    "                print(f'\\nExemple de TN (Texte de Corneille, bien identifié, score Molière: {round(score_moliere,4)}, score Corneille: {round(score_corneille,4)}):\\n{t}\\n')\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "    \n",
    "def prediction_moliere_vs_corneille_1ere_caracteristique(most_common_count, verbose: bool = False) -> Tuple[float,float]:\n",
    "    random.seed(42)\n",
    "    if verbose: \n",
    "        print(f'\\nMoliere Dataset: {paragraph_count(moliere_dataset)} paragraphes ({word_count(moliere_dataset)} mots) venant de {len(moliere_dataset)} oeuvres:\\n{list(moliere_dataset.keys())}')\n",
    "        print(f'\\nCorneille Dataset: {paragraph_count(corneille_dataset)} paragraphes ({word_count(corneille_dataset)} mots) venant de {len(corneille_dataset)} oeuvres:\\n{list(corneille_dataset.keys())}')\n",
    "\n",
    "    train_moliere,validation_moliere,train_corneille,validation_corneille = split_train_validation_all_authors(moliere_dataset, corneille_dataset, percentage_in_train)\n",
    "\n",
    "    if verbose: \n",
    "        print(f'\\nMoliere Train Dataset: {paragraph_count(train_moliere)} paragraphes ({word_count(train_moliere)} mots) venant de {len(train_moliere)} oeuvres:\\n{list(train_moliere.keys())}')\n",
    "        print(f'\\nMoliere Validation Dataset: {paragraph_count(validation_moliere)} paragraphes ({word_count(validation_moliere)} mots) venant de {len(validation_moliere)} oeuvres:\\n{list(validation_moliere.keys())}')\n",
    "        print(f'\\nCorneille Train Dataset: {paragraph_count(train_corneille)} paragraphes ({word_count(train_corneille)} mots) venant de {len(train_corneille)} oeuvres:\\n{list(train_corneille.keys())}')\n",
    "        print(f'\\nCorneille Validation Dataset: {paragraph_count(validation_corneille)} paragraphes ({word_count(validation_corneille)} mots) venant de {len(validation_corneille)} oeuvres:\\n{list(validation_corneille.keys())}')\n",
    "\n",
    "    train_normalized_words_to_stats_moliere = compute_normalized_words_to_stats(all_paragraphs(train_moliere))\n",
    "    train_normalized_words_to_stats_corneille = compute_normalized_words_to_stats(all_paragraphs(train_corneille))\n",
    "\n",
    "    # we only keep the most common words\n",
    "    train_most_common_moliere = compute_most_common_normalized_words(train_normalized_words_to_stats_moliere, most_common_count)\n",
    "    train_most_common_corneille = compute_most_common_normalized_words(train_normalized_words_to_stats_corneille, most_common_count)\n",
    "    train_error = compute_error(*compute_confusion_matrix_all_authors(all_paragraphs(train_moliere), all_paragraphs(train_corneille), train_most_common_moliere , train_most_common_corneille, verbose))\n",
    "    validation_error = compute_error(*compute_confusion_matrix_all_authors(all_paragraphs(validation_moliere), all_paragraphs(validation_corneille), train_most_common_moliere , train_most_common_corneille, verbose))\n",
    "    return train_error, validation_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e576ae3",
   "metadata": {},
   "source": [
    "## Résultats de cette méthode (basée sur la 1ère caractéristique) en ayant choisit les 50 mots les plus courants de chaque auteur comme leurs mots signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476674c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_error,validation_error) = prediction_moliere_vs_corneille_1ere_caracteristique(most_common_normalized_words_count)\n",
    "print(f'Erreur(Molière ou Corneille?)= {round(100*validation_error,1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc47f13",
   "metadata": {},
   "source": [
    "## Pour améliorer ces résultats, on peut proposer à l'étudiant de modifier le nombre de mots signatures associés à chaque auteur (ci dessus: 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841b52",
   "metadata": {},
   "source": [
    "### On affiche à l'étudiant la valeur de l'erreur pour différentes valeurs du nombre de mots signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8d08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common_counts = [50,1000]+list(range(2000,16000+1,2000))\n",
    "error_for_most_common_counts = []\n",
    "for most_common_count in most_common_counts:\n",
    "    (train_error,validation_error) = prediction_moliere_vs_corneille_1ere_caracteristique(most_common_count)\n",
    "    print(f'Erreur(Molière ou Corneille?) if most_common_count={most_common_count} = {round(100*validation_error,1)}%')\n",
    "    error_for_most_common_counts.append(validation_error)\n",
    "\n",
    "# le code ci dessous (commenté) permet d'éviter de recalculer les valeurs\n",
    "#print(most_common_counts)\n",
    "#print(error_for_most_common_counts)\n",
    "#most_common_counts = [50, 1000, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000, 18000]\n",
    "#error_for_most_common_counts = [0.0738255033557047, 0.030201342281879207, 0.01342281879194629, 0.010067114093959773, 0.02684563758389258, 0.023489932885906062, 0.043624161073825496, 0.05033557046979864, 0.06375838926174493, 0.06375838926174493, 0.06375838926174493]\n",
    "\n",
    "x_dense = np.linspace(min(most_common_counts), max(most_common_counts), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(most_common_counts, error_for_most_common_counts)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(most_common_counts, error_for_most_common_counts, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlim(0, max(most_common_counts))\n",
    "plt.xlabel('Nombres de mots signatures chez chaque auteur', fontsize=20)\n",
    "plt.ylabel('Erreur pour distinguer des oeuvres de Molière et Corneille', fontsize=20)\n",
    "plt.title(\"Evolution de l'erreur en fonction du nombre de mots signatures chez chaque auteur\", fontsize=20)\n",
    "plt.legend()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf346fa",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#la caractéristique à améliorer\n",
    "# ce '50' sera modifé par l'étudiant\n",
    "nombre_de_mots_signatures_chez_chaque_auteur = 50\n",
    "\n",
    "(train_error,validation_error) = prediction_moliere_vs_corneille_1ere_caracteristique(nombre_de_mots_signatures_chez_chaque_auteur)\n",
    "print()\n",
    "print('-'*80)\n",
    "print(f'Erreur(Molière ou Corneille?)={round(100*validation_error,1)}%')\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799f351",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 60px;\"><b>2ème caractéristique</b></span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 28px;\">Le nombre de mots (dans un texte donné) nettement plus fréquents chez un auteur par rapport à un autre.</span><br>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\"><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49cf1d",
   "metadata": {},
   "source": [
    "# PRIVE: outil de recherche de textes très spécifiques à Molière ou Corneille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_score_moliere_vs_corneille(count_moliere:int, total_words_moliere:int, count_corneille:int, total_words_corneille:int ):\n",
    "    if count_moliere+count_corneille<30:\n",
    "        return 0\n",
    "    if count_moliere == 0:\n",
    "        return -1\n",
    "    if count_corneille == 0:\n",
    "        return 1\n",
    "    percentage_moliere = count_moliere/total_words_moliere\n",
    "    percentage_corneille = count_corneille/total_words_corneille\n",
    "    if percentage_moliere>2*percentage_corneille:\n",
    "        return 1\n",
    "    if percentage_corneille>2*percentage_moliere:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def find_most_distinctive_lines(is_moliere: bool) -> None:\n",
    "    min_score_moliere = 0\n",
    "    max_score_moliere = 0\n",
    "    \n",
    "    author_dataset = moliere_dataset if is_moliere else corneille_dataset\n",
    "    \n",
    "    for book_name, paragraphs in author_dataset.items():\n",
    "        for paragraph in paragraphs:\n",
    "            for line in paragraph.splitlines():\n",
    "                words = split_text(line)\n",
    "                if len(words)<5:\n",
    "                    continue\n",
    "                line_score_moliere_vs_corneille = 0\n",
    "                comment_moliere = \"\"\n",
    "                comment_corneille = \"\"\n",
    "                for original_word in words:\n",
    "                    normalized_word = compute_normalized_word(original_word)\n",
    "                    count_moliere = stats_moliere[normalized_word][0] if normalized_word in stats_moliere else 0\n",
    "                    count_corneille = stats_corneille[normalized_word][0] if normalized_word in stats_corneille else 0\n",
    "                    word_score_moliere_vs_corneille = compute_word_score_moliere_vs_corneille(count_moliere, moliere_total_word_count, count_corneille, corneille_total_word_count)\n",
    "                    if word_score_moliere_vs_corneille == 0:\n",
    "                        continue\n",
    "                    if is_moliere:\n",
    "                        comment = f\"{original_word} ({count_moliere} vs {count_corneille}) \"\n",
    "                    else:\n",
    "                        comment = f\"{original_word} ({count_corneille} vs {count_moliere}) \"\n",
    "                    if word_score_moliere_vs_corneille>0:\n",
    "                        comment_moliere += comment\n",
    "                    else:\n",
    "                        comment_corneille += comment\n",
    "                    line_score_moliere_vs_corneille += word_score_moliere_vs_corneille\n",
    "                if is_moliere and comment_corneille:\n",
    "                    continue\n",
    "                if not is_moliere and comment_moliere:\n",
    "                    continue\n",
    "                if abs(line_score_moliere_vs_corneille)>=5 and (len(comment_moliere)==0 or len(comment_corneille)==0):\n",
    "                #if total_score_moliere<min_score_moliere or line_score_moliere_vs_corneille>max_score_moliere:\n",
    "                    min_score_moliere = min(min_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    max_score_moliere = max(max_score_moliere,line_score_moliere_vs_corneille)\n",
    "                    print('-'*50)\n",
    "                    print(f\"Oeuvre de {'Molière' if is_moliere else 'Corneille'}: {book_name}\")\n",
    "                    print(line)\n",
    "                    print(f'Score: {line_score_moliere_vs_corneille}')\n",
    "                    if comment_moliere:\n",
    "                        print(f'avantage Molière: {comment_moliere}')\n",
    "                    if comment_corneille:\n",
    "                        print(f'avantage Corneille: {comment_corneille}')\n",
    "                    print('-'*50)\n",
    "                    print()\n",
    "\n",
    "'''\n",
    "Exemples de textes trouvés par cet outil:\n",
    "\n",
    "--------------------------------------------------\n",
    "Oeuvre de Molière: le_malade_imaginaire\n",
    "Qu'il se fasse médecin, je consens au mariage. Oui, faites-vous médecin, je vous donne ma fille.\n",
    "Score: 5\n",
    "avantage Molière: médecin (208 vs 1) mariage (181 vs 24) Oui (849 vs 165) médecin (208 vs 1) fille (415 vs 128) \n",
    "\n",
    "--------------------------------------------------\n",
    "Oeuvre de Corneille: polyeucte\n",
    "Ton courage était bon, ton devoir l'a trahi.\n",
    "Score: -7\n",
    "avantage Corneille: Ton (759 vs 224) courage (206 vs 44) était (86 vs 1) ton (759 vs 224) devoir (182 vs 69) l'a (121 vs 72) trahi (22 vs 8) \n",
    "'''                    \n",
    "                    \n",
    "                \n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Molière')\n",
    "find_most_distinctive_lines(True)\n",
    "print()\n",
    "print('-'*50)\n",
    "print('Recherche de lignes spécifiques à Corneille')\n",
    "find_most_distinctive_lines(False)\n",
    "print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12032ba7",
   "metadata": {},
   "source": [
    "# Mise en situation:\n",
    "## On veut identifier les auteurs des 2 phrases suivantes:\n",
    "### - Oui, faites-vous médecin, je vous donne ma fille.\n",
    "### - Ton courage était bon, ton devoir l'a trahi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a5dad",
   "metadata": {},
   "source": [
    "## On montre les fréquences d'apparition de certains mots chez Molière et Corneille "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ecff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots = ['courage', 'devoir', 'fille', 'médecin', 'oui', 'trahi']\n",
    "\n",
    "'''\n",
    "for word in mots:\n",
    "    normalized_word = compute_normalized_word(word)\n",
    "    print(f\"Le mot '{word}':\")\n",
    "    print(f'\\test présent {stats_moliere[normalized_word][0]} fois chez Molière:  ', stats_moliere[normalized_word][1])\n",
    "    print(f'\\test présent {stats_corneille[normalized_word][0]} fois chez Corneille:', stats_corneille[normalized_word][1])\n",
    "'''\n",
    "df = create_table_with_occurences_corneille_moliere(mots)\n",
    "\n",
    "def format_percentage(value):\n",
    "    return f'{round(100*value,3)}%'\n",
    "\n",
    "df['Fréquence chez Molière'] = df['Fréquence Molière'].apply(format_percentage)\n",
    "df['Fréquence chez Corneille'] = df['Fréquence Corneille'].apply(format_percentage)\n",
    "df[['Fréquence chez Molière', 'Fréquence chez Corneille']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8c327",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Oui, faites-vous médecin, je vous donne ma fille.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e38ca8",
   "metadata": {},
   "source": [
    "## En se basant sur le tableau d'occurences ci dessus, qui de Molière ou Corneille a probalement écrit cette ligne:\n",
    "### \"Ton courage était bon, ton devoir l'a trahi.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer le \"XXX\" ci dessous par \"Molière\" ou par \"Corneille\"\n",
    "auteur = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b5ca3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">4ème partie: </span><span style=\"font-size: 36px;\">(basée sur la 2ème caractéristique)</span><br><br>\n",
    "<span style=\"font-size: 36px;\">Déterminer si un texte a été écrit par Molière ou Corneille.</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 24px;\"><u>Méthode utilisée:</u></span><br>\n",
    "<span style=\"font-size: 24px;\">1. Pour chaque mot du texte, on calcule sa fréquence d'apparition chez Molière et chez Corneille.</span><br>\n",
    "<span style=\"font-size: 24px;\">2. On calcule le nombre de mots de ce texte 2 fois plus fréquents chez Molière que chez Corneille.</span><br>\n",
    "<span style=\"font-size: 24px;\">3. On calcule le nombre de mots de ce texte 2 fois plus fréquents chez Corneille que chez Molière.</span><br>\n",
    "<span style=\"font-size: 24px;\">4. On attribue le texte à l'auteur ayant le plus de mots plus fréquents chez lui.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_valeur_2eme_caracteristique_moliere_et_corneille(text:str, train_stats_moliere, train_stats_corneille, moliere_word_count, corneille_word_count, multiplier: float) -> Tuple[int,int]:\n",
    "    valeur_2eme_caracteristique_moliere = 0\n",
    "    valeur_2eme_caracteristique_corneille = 0\n",
    "    for original_word in split_text(text):\n",
    "        normalized_word = compute_normalized_word(original_word)\n",
    "        if normalized_word in stop_words:\n",
    "            continue\n",
    "        frequency_moliere = 0\n",
    "        if normalized_word in train_stats_moliere:\n",
    "            frequency_moliere = train_stats_moliere[normalized_word][0]/moliere_total_word_count_without_stopwords\n",
    "        frequency_corneille = 0\n",
    "        if normalized_word in train_stats_corneille:\n",
    "            frequency_corneille = train_stats_corneille[normalized_word][0]/corneille_total_word_count_without_stopwords\n",
    "        if frequency_moliere>(multiplier*frequency_corneille):\n",
    "            valeur_2eme_caracteristique_moliere += 1\n",
    "        if frequency_corneille>(multiplier*frequency_moliere):\n",
    "            valeur_2eme_caracteristique_corneille += 1\n",
    "    return valeur_2eme_caracteristique_moliere,valeur_2eme_caracteristique_corneille\n",
    "\n",
    "def compute_confusion_matrix_all_authors_frequency(text_moliere: List[str], text_corneille: List[str], train_stats_moliere, train_stats_corneille, multiplier: float) ->Tuple[int,int,int,int]:\n",
    "    TP = 0 # y_true = Molière ,  y_pred = Molière\n",
    "    TN = 0 # y_true = Corneille, y_pred = Corneille\n",
    "    FN = 0 # y_true = Molière,   y_pred = Corneille\n",
    "    FP = 0 # y_true = Corneille, y_pred = Molière \n",
    "    \n",
    "    moliere_word_count = sum([stats[0] for normalized_word,stats in train_stats_moliere.items() if normalized_word not in stop_words])\n",
    "    corneille_word_count = sum([stats[0] for normalized_word,stats in train_stats_corneille.items() if normalized_word not in stop_words])\n",
    "    for t in text_moliere:\n",
    "        (valeur_2eme_caracteristique_moliere,valeur_2eme_caracteristique_corneille) = calcul_valeur_2eme_caracteristique_moliere_et_corneille(t, train_stats_moliere, train_stats_corneille, moliere_word_count, corneille_word_count, multiplier)\n",
    "        if valeur_2eme_caracteristique_moliere>valeur_2eme_caracteristique_corneille:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    for t in text_corneille:\n",
    "        (valeur_2eme_caracteristique_moliere,valeur_2eme_caracteristique_corneille) = calcul_valeur_2eme_caracteristique_moliere_et_corneille(t, train_stats_moliere, train_stats_corneille, moliere_word_count, corneille_word_count, multiplier)\n",
    "        if valeur_2eme_caracteristique_moliere>valeur_2eme_caracteristique_corneille:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    return (TP,TN,FP,FN)\n",
    "        \n",
    "    \n",
    "def prediction_moliere_vs_corneille_2eme_caracteristique(multiplier: float) -> Tuple[float,float]:\n",
    "    random.seed(42)\n",
    "    train_moliere,validation_moliere,train_corneille,validation_corneille = split_train_validation_all_authors(moliere_dataset, corneille_dataset, percentage_in_train)\n",
    "    train_stats_moliere = compute_normalized_words_to_stats(all_paragraphs(train_moliere))\n",
    "    train_stats_corneille = compute_normalized_words_to_stats(all_paragraphs(train_corneille))\n",
    "    train_error = compute_error(*compute_confusion_matrix_all_authors_frequency(all_paragraphs(train_moliere), all_paragraphs(train_corneille), train_stats_moliere, train_stats_corneille, multiplier))\n",
    "    validation_error = compute_error(*compute_confusion_matrix_all_authors_frequency(all_paragraphs(validation_moliere), all_paragraphs(validation_corneille), train_stats_moliere, train_stats_corneille, multiplier))\n",
    "    return train_error, validation_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d54848",
   "metadata": {},
   "source": [
    "## Affichage d'une courbe permettant de choisir la valeur optimale du coéfficient 'K' à partir duquel on considére un mot beaucoup plus courant chez l'un des auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fbd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multipliers = list(range(1, 7+1))\n",
    "\n",
    "error_for_multipliers = []\n",
    "for multiplier in multipliers:\n",
    "    (train_error,validation_error) = prediction_moliere_vs_corneille_2eme_caracteristique(multiplier)\n",
    "    print(f'Erreur(Molière ou Corneille?) if multiplier={multiplier} = {round(100*validation_error,1)}%')\n",
    "    error_for_multipliers.append(validation_error)\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min(multipliers), max(multipliers), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(multipliers, error_for_multipliers)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(multipliers, error_for_multipliers, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlim(min(multipliers), max(multipliers))\n",
    "plt.xlabel('Coéfficient K (à partir duquel on considére un mot nettement plus fréquent chez auteur)', fontsize=20)\n",
    "plt.ylabel('Erreur pour distinguer des oeuvres de Molière et Corneille', fontsize=20)\n",
    "plt.title(\"Evolution de l'erreur en fonction de ce coéfficient K\", fontsize=20)\n",
    "plt.legend()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bb306",
   "metadata": {},
   "source": [
    "## On propose à l'étudiant de choisir la valeur de la caractéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9745d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#la caractéristique à améliorer\n",
    "# ce '2' sera modifé par l'étudiant\n",
    "multiplier = 2\n",
    "(train_error,validation_error) = prediction_moliere_vs_corneille_2eme_caracteristique(multiplier)\n",
    "print(f'Erreur(Molière ou Corneille?)= {round(100*validation_error,1)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721f0fd",
   "metadata": {},
   "source": [
    "## PRIVE: Erreur pour chaque oeuvre utilisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6aa076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_most_common_normalized_words_count = 3500\n",
    "most_common_moliere = compute_most_common_normalized_words(stats_moliere, optimal_most_common_normalized_words_count)\n",
    "most_common_corneille = compute_most_common_normalized_words(stats_corneille, optimal_most_common_normalized_words_count)\n",
    "\n",
    "print('-'*80+'\\nErreur pour chaque oeuvre de Moliere\\n'+'-'*80)\n",
    "error_moliere = dict()\n",
    "for book_path in all_txt_files_in_directory(os.path.join(directory, 'moliere')):\n",
    "    (TP,TN,FP,FN) = compute_confusion_matrix_all_authors(split_book_into_paragraphs(book_path), [], most_common_moliere , most_common_corneille, 0)\n",
    "    #print(f\"Error '{pathlib.Path(book_path).stem}': {round(compute_error(TP,TN,FP,FN),4)}\")\n",
    "    error_moliere[pathlib.Path(book_path).stem] = compute_error(TP,TN,FP,FN)\n",
    "for e in sorted(error_moliere.items(), key=lambda x: x[1]):\n",
    "    print(e)\n",
    "\n",
    "print()\n",
    "print('-'*80+'\\nErreur pour chaque oeuvre de Corneille\\n'+'-'*80)\n",
    "erreur_corneille = dict()\n",
    "for book_path in all_txt_files_in_directory(os.path.join(directory, 'corneille')):\n",
    "    (TP,TN,FP,FN) = compute_confusion_matrix_all_authors([], split_book_into_paragraphs(book_path), most_common_moliere , most_common_corneille, 0)\n",
    "    erreur_corneille[pathlib.Path(book_path).stem] = compute_error(TP,TN,FP,FN)\n",
    "for e in sorted(erreur_corneille.items(), key=lambda x: x[1]):\n",
    "    print(e)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
